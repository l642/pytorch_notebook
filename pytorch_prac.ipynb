{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab124fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e932c00",
   "metadata": {},
   "source": [
    "# Tensor basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8ab5d",
   "metadata": {},
   "source": [
    "#### torch.empty() creates tensor with any data type you want, torch.Tensor() only creates tensors of type torch.FloatTensor. So torch.Tensor() is a special case of torch.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb76828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([-1.7806e+27])\n",
      "b: tensor([-1.7806e+27,  4.5698e-41, -2.9059e+07])\n",
      "c: tensor([[-1.7806e+27,  4.5698e-41],\n",
      "        [-2.9109e+07,  3.0733e-41]])\n",
      "d: tensor([[[-1.7806e+27,  4.5698e-41],\n",
      "         [-2.9119e+07,  3.0733e-41],\n",
      "         [ 1.4013e-45,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00]]])\n",
      "tpye of empty tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "##creating empty tensor\n",
    "a=torch.empty(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.empty(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.empty(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.empty(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "print('tpye of empty tensor:', d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd08aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0.7403])\n",
      "b: tensor([0.4947, 0.9709, 0.4873])\n",
      "c: tensor([[0.5341, 0.2587],\n",
      "        [0.4076, 0.8059]])\n",
      "d: tensor([[[0.0275, 0.5968],\n",
      "         [0.7773, 0.7455],\n",
      "         [0.3259, 0.2409]],\n",
      "\n",
      "        [[0.6497, 0.7031],\n",
      "         [0.7782, 0.6036],\n",
      "         [0.4873, 0.3317]]])\n",
      "tpye of rand tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "##creating tensor with random values\n",
    "a=torch.rand(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.rand(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.rand(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.rand(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "print('tpye of rand tensor:', d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e379be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0.])\n",
      "b: tensor([0., 0., 0.])\n",
      "c: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "d: tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "e: tensor([1.])\n",
      "f: tensor([1., 1., 1.])\n",
      "g: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "h: tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "## torch with zeros and ones\n",
    "a=torch.zeros(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.zeros(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.zeros(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.zeros(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "\n",
    "e=torch.ones(1)   #scaler\n",
    "print('e:',e)\n",
    "f=torch.ones(3)   #1-D\n",
    "print('f:',f)\n",
    "g=torch.ones(2,2)  #2-D\n",
    "print('g:',g)\n",
    "h=torch.ones(2,3,2) #3-D\n",
    "print('h:',h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c742458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e9458ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "c: tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float16)\n",
      "d: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "##changing data type\n",
    "b=torch.ones(2,2, dtype=torch.int)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.ones(2,2, dtype=torch.float16)   #1-D\n",
    "print('c:',c)\n",
    "d=torch.ones(2,2, dtype=torch.int16)   #1-D\n",
    "print('d:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ba9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "size of b: torch.Size([2, 2])\n",
      "size of b torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "##size of tensor\n",
    "b=torch.ones(2,2, dtype=torch.int)   #1-D\n",
    "print('b:',b)\n",
    "print('size of b:', b.size())\n",
    "print('size of b',b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93bf204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2100, 12.0000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "##another way of creating a tensor\n",
    "\n",
    "a=torch.tensor([1.21,12,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "645558b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0.3676, 0.4455],\n",
      "        [0.4191, 0.4266]])\n",
      "y: tensor([[0.0511, 0.8247],\n",
      "        [0.0444, 0.7447]])\n",
      "a tensor([[0.4187, 1.2702],\n",
      "        [0.4635, 1.1713]])\n",
      "b: tensor([[ 0.3165, -0.3792],\n",
      "        [ 0.3746, -0.3181]])\n",
      "c: tensor([[0.0188, 0.3674],\n",
      "        [0.0186, 0.3177]])\n",
      "d: tensor([[7.1987, 0.5402],\n",
      "        [9.4289, 0.5729]])\n"
     ]
    }
   ],
   "source": [
    "##operation on tensors\n",
    "x=torch.rand(2,2)\n",
    "y=torch.rand(2,2)\n",
    "print('x:',x)\n",
    "print('y:',y)\n",
    "\n",
    "a=x+y\n",
    "a=torch.add(x,y)\n",
    "print('a',a)\n",
    "\n",
    "b=x-y\n",
    "a=torch.sub(x,y)\n",
    "print('b:',b)\n",
    "\n",
    "c=x*y\n",
    "a=torch.mul(x,y)\n",
    "print('c:',c)\n",
    "\n",
    "d=x/y\n",
    "a=torch.div(x,y)\n",
    "print('d:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7571f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8442, 0.5387, 0.9402],\n",
      "        [0.7159, 0.9412, 0.7024],\n",
      "        [0.5917, 0.5546, 0.9049],\n",
      "        [0.5859, 0.2922, 0.0793],\n",
      "        [0.9103, 0.8070, 0.2382]])\n",
      "first row     : tensor([0.8442, 0.5387, 0.9402])\n",
      "first column  : tensor([0.8442, 0.7159, 0.5917, 0.5859, 0.9103])\n",
      "first two row : tensor([[0.8442, 0.5387, 0.9402],\n",
      "        [0.7159, 0.9412, 0.7024]])\n",
      "first two columns : tensor([[0.8442, 0.5387],\n",
      "        [0.7159, 0.9412],\n",
      "        [0.5917, 0.5546],\n",
      "        [0.5859, 0.2922],\n",
      "        [0.9103, 0.8070]])\n",
      "last row: tensor([0.9103, 0.8070, 0.2382])\n",
      "last column: tensor([0.9402, 0.7024, 0.9049, 0.0793, 0.2382])\n",
      "tensor(0.8442)\n",
      "tensor(0.9049)\n",
      "0.8441579341888428\n",
      "0.904884397983551\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(5,3)\n",
    "print(x)\n",
    "print('first row     :',x[0,:])\n",
    "print('first column  :',x[:,0])\n",
    "print('first two row :',x[0:2,:])\n",
    "print('first two columns :',x[:,0:2])\n",
    "print('last row:',x[-1,:])\n",
    "print('last column:',x[:,-1])\n",
    "\n",
    "#printing specific value from tensor\n",
    "a=x[0,0]\n",
    "print(a)\n",
    "b=x[2,2]\n",
    "print(b)\n",
    "\n",
    "#printing actual value from tensor(item only availabe for scaler values)\n",
    "print(x[0,0].item())\n",
    "print(x[2,2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df0d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230],\n",
      "        [0.7598, 0.0444, 0.4070, 0.5096],\n",
      "        [0.3600, 0.0053, 0.2266, 0.7698],\n",
      "        [0.3549, 0.6818, 0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667],\n",
      "        [0.0482, 0.9230],\n",
      "        [0.7598, 0.0444],\n",
      "        [0.4070, 0.5096],\n",
      "        [0.3600, 0.0053],\n",
      "        [0.2266, 0.7698],\n",
      "        [0.3549, 0.6818],\n",
      "        [0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230, 0.7598, 0.0444, 0.4070, 0.5096],\n",
      "        [0.3600, 0.0053, 0.2266, 0.7698, 0.3549, 0.6818, 0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230, 0.7598, 0.0444, 0.4070, 0.5096, 0.3600,\n",
      "         0.0053, 0.2266, 0.7698, 0.3549, 0.6818, 0.3928, 0.6209]])\n"
     ]
    }
   ],
   "source": [
    "##changing dimension of tensor\n",
    "a=torch.rand(4,4)\n",
    "print(a)\n",
    "b=a.view(8,2)\n",
    "print(b)\n",
    "c=a.view(2,-1) ##after giving first dimension it will automatically detect 2 dimension\n",
    "print(c)\n",
    "d=a.view(16,-1) ##after giving first dimension it will automatically detect 2 dimension\n",
    "print(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73d1bf8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 100, 100])\n",
      "torch.Size([4, 256, 10000])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([4,256,100,100])\n",
    "print(x.shape)\n",
    "y=x.view(x.size(0),x.size(1),-1)\n",
    "print(y.shape)\n",
    "z=torch.mean(y,dim=2)\n",
    "print(z.shape)\n",
    "z1=torch.mean(x.view(x.shape[0],x.shape[1],-1),dim=2)\n",
    "print(z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tensor to numpy \n",
    "import numpy as np\n",
    "a=torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print('*'*20)\n",
    "p=a.numpy()\n",
    "print(p)\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2de536fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(2,2)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99ab9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "********************\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#numpy to tensor\n",
    "a=np.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print('*'*20)\n",
    "b=torch.from_numpy(a)\n",
    "print(b)\n",
    "print(type(b))\n",
    "###NOTE:-the tensor can be converted to numpy only if device is cpu not on gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c4213",
   "metadata": {},
   "source": [
    "# Checking GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e54135fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###cheching whether GPU is avalable or not\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901c98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0.4963, 0.3218, 0.1832, 0.1560, 0.6700])\n",
      "tensor([1.4963, 1.3218, 1.1832, 1.1560, 1.6700])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "else:\n",
    "    device=torch.device(\"cpu\")\n",
    "    x=torch.ones(5,device=device)\n",
    "    print(x)\n",
    "    y=torch.rand(5)\n",
    "    print(y)\n",
    "    y=y.to(device)\n",
    "\n",
    "    z=x+y\n",
    "    \n",
    "    print(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e3102",
   "metadata": {},
   "source": [
    "# Gradient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2424e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9666, 0.2050, 0.3420], requires_grad=True)\n",
      "tensor(12.7650, grad_fn=<MeanBackward0>)\n",
      "tensor([3.9554, 2.9400, 3.1226])\n"
     ]
    }
   ],
   "source": [
    "###Gradient Calculations\n",
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "z=y*y*2\n",
    "z=z.mean()\n",
    "print(z)\n",
    "z.backward() ### means z(scaler) is the error or difference and we have to find grad of z w.r.t x\n",
    "#(When we call .backward() on z, autograd calculates these gradients and stores them in the respective tensorsâ€™ .grad attribute.)\n",
    "print(x.grad)   ######dz/dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51456b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5575, 0.2967, 0.0163], requires_grad=True)\n",
      "tensor([13.0815, 10.5500,  8.1308], grad_fn=<MulBackward0>)\n",
      "tensor([10.2300,  1.8374,  2.4195])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "z=y*y*2\n",
    "#z=z.mean()\n",
    "print(z)\n",
    "u=torch.tensor([1.0,0.2,0.3],dtype=torch.float32)\n",
    "z.backward(u) ### jacobioan (dz/du)\n",
    "print(x.grad)   ######dz/dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c9507",
   "metadata": {},
   "source": [
    "# To stop a tensor tracking the gradient\n",
    "## 1. x.require_grad_(false)\n",
    "## 2. x.detach()\n",
    "## 3. with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a0e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6579, 0.6068, 0.9234], requires_grad=True)\n",
      "tensor([0.6579, 0.6068, 0.9234])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b04b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4569, 0.2485, 0.2689, 0.7756], requires_grad=True)\n",
      "tensor([0.4569, 0.2485, 0.2689, 0.7756])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(4,requires_grad=True)\n",
    "print(y)\n",
    "y=y.detach()\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e907b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3078, 0.1705, 0.4481], requires_grad=True)\n",
      "tensor([2.3078, 2.1705, 2.4481])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y=x+2\n",
    "print(y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfee0cf",
   "metadata": {},
   "source": [
    "# weight.zero.grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "075e8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Without zero.grad_()\n",
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    out=(weights*3).sum()\n",
    "    #print(out)\n",
    "    out.backward()\n",
    "    print(weights.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8058f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# With zero.grad_()\n",
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    out=(weights*3).sum()\n",
    "    #print(out)\n",
    "    out.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdecb61",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cbbdca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "###Back propagation\n",
    "x=torch.tensor([1.0])\n",
    "y=torch.tensor([2.0])\n",
    "w=torch.tensor([1.0],requires_grad=True)\n",
    "y_hat=x*w\n",
    "d=y_hat-y\n",
    "loss=d**2\n",
    "##backward propagation\n",
    "loss.backward() ##error\n",
    "print(w.grad) ##dl/dw=(dl/dd)*(dd/dy_hat)*dy_hat/dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab298af",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "016f7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch=1, w = 1.200, loss = 30.00000000\n",
      "epoch=3, w = 1.872, loss = 0.76800019\n",
      "epoch=5, w = 1.980, loss = 0.01966083\n",
      "epoch=7, w = 1.997, loss = 0.00050332\n",
      "epoch=9, w = 1.999, loss = 0.00001288\n",
      "epoch=11, w = 2.000, loss = 0.00000033\n",
      "epoch=13, w = 2.000, loss = 0.00000001\n",
      "epoch=15, w = 2.000, loss = 0.00000000\n",
      "epoch=17, w = 2.000, loss = 0.00000000\n",
      "epoch=19, w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "#####Gradientdescent_manually\n",
    "import numpy as np \n",
    "\n",
    "# Compute every step manually\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# J = MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2x(w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # calculate gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch={epoch+1}, w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2aba16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "###gradientdescent_auto\n",
    "\n",
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor([0.0],requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "def loss(y,y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "lr=0.1\n",
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10== 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedad458",
   "metadata": {},
   "source": [
    "# Training Pipeline: Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7b319413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 3.000, loss = 30.00000000\n",
      "epoch 11: w = 2.001, loss = 0.00002861\n",
      "epoch 21: w = 2.000, loss = 0.00000000\n",
      "epoch 31: w = 2.000, loss = 0.00000000\n",
      "epoch 41: w = 2.000, loss = 0.00000000\n",
      "epoch 51: w = 2.000, loss = 0.00000000\n",
      "epoch 61: w = 2.000, loss = 0.00000000\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "###Training Pipeline: Model, Loss, and Optimizer\n",
    "import torch.nn as nn\n",
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor([0.0],requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "lr=0.1\n",
    "loss=nn.MSELoss()    ###using loss as predefined\n",
    "optimizer=torch.optim.SGD([w],lr=lr)   ##optimizer\n",
    "\n",
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10== 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9a825c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "epochs:1, loss:54.546833\n",
      "epochs:11, loss:0.065913\n",
      "epochs:21, loss:0.026023\n",
      "epochs:31, loss:0.014166\n",
      "epochs:41, loss:0.007713\n",
      "epochs:51, loss:0.004200\n",
      "epochs:61, loss:0.002287\n",
      "epochs:71, loss:0.001245\n",
      "epochs:81, loss:0.000678\n",
      "epochs:91, loss:0.000369\n",
      "Prediction after training = 9.976\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "#print(x.shape)\n",
    "n_samples,n_features=x.shape[0],x.shape[1]\n",
    "print(n_samples,n_features)\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "model=nn.Linear(input_size,output_size)\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "n_epochs=100\n",
    "for epoch in range(n_epochs):\n",
    "    output=model(x)\n",
    "    #print(output)\n",
    "    #print(output.shape)\n",
    "    l=loss(y,output)\n",
    "    #print(l.item())\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"epochs:{epoch+1}, loss:{l.item():3f}\")\n",
    "print(f'Prediction after training = {model(x_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f328128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "epochs:1, loss:20.859375\n",
      "epochs:11, loss:0.157385\n",
      "epochs:21, loss:0.081965\n",
      "epochs:31, loss:0.044627\n",
      "epochs:41, loss:0.024298\n",
      "epochs:51, loss:0.013230\n",
      "epochs:61, loss:0.007203\n",
      "epochs:71, loss:0.003922\n",
      "epochs:81, loss:0.002135\n",
      "epochs:91, loss:0.001163\n",
      "Prediction after training = 9.957\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "#print(x.shape)\n",
    "n_samples,n_features=x.shape[0],x.shape[1]\n",
    "print(n_samples,n_features)\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "class LinearReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearReg,self).__init__()\n",
    "        \n",
    "        self.Lin=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.Lin(x)\n",
    "        return x\n",
    "model=LinearReg()   \n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "n_epochs=100\n",
    "for epoch in range(n_epochs):\n",
    "    output=model(x)\n",
    "    #print(output)\n",
    "    #print(output.shape)\n",
    "    l=loss(y,output)\n",
    "    #print(l.item())\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"epochs:{epoch+1}, loss:{l.item():3f}\")\n",
    "print(f'Prediction after training = {model(x_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ed5e8",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a597e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normal Folder wise\n",
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,path='/home/arvind/Videos/classification/test',augmentation=True,dim=(100,100)):\n",
    "        self.dim=dim\n",
    "        self.img_list=glob.glob('/home/arvind/Videos/classification/test/**/**')\n",
    "        #self.label=[i.split('/')[-2] for i in self.img_list]\n",
    "        self.dict={\"building\":0,\"forest\":1}\n",
    "        self.augmentation=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.2),\n",
    "        #GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.2)\n",
    "        ],p=0.6)\n",
    "    def augment(self,img):\n",
    "        aug_img=self.augmentation(image=img)\n",
    "        return aug_img['image'] \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.img_list[index]\n",
    "        labels=img.split('/')[-2]\n",
    "        img=Image.open(img)\n",
    "        img = img.resize(self.dim)\n",
    "        img=np.asarray(img)/255\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img=self.augment(img)\n",
    "        labels=self.dict[labels]\n",
    "        return torch.FloatTensor(img.transpose(2,0,1)),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "train=DataLoader(Train(path='/home/arvind/Videos/intel/train/**/**'),batch_size=4)\n",
    "for image, label in train:\n",
    "    print(image.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2e3730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSV \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from albumentations import *\n",
    "class Train(Dataset):\n",
    "    def __init__(self,csv_path=\"/home/arvind/Videos/classification/testing.csv\",augment=True,dim=(500,500),batch_size=4):\n",
    "        self.batch_size=batch_size\n",
    "        self.dim=dim\n",
    "        self.df=pd.read_csv('/home/arvind/Videos/classification/testing.csv')\n",
    "        self.image=self.df['path'].tolist()\n",
    "        self.label=self.df['label'].tolist()\n",
    "        self.dict={'forest':0,'building':1}\n",
    "        self.aug=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),],p=0.6)\n",
    "    \n",
    "    def augmentation(self,img):\n",
    "        img=self.aug(image=img)\n",
    "        return aug['image']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.image[index]\n",
    "        label=self.label[index]\n",
    "        labels=self.dict[label]\n",
    "        img=Image.open(img)\n",
    "        img=img.resize(self.dim)\n",
    "        img=np.asarray(img)\n",
    "        if selg.augment:\n",
    "            img=self.augmentation(img)\n",
    "            \n",
    "        return torch.FloatTensor(img.transpose(2,0,1)),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "        \n",
    "        \n",
    "        \n",
    "train=DataLoader(Train(csv_path=\"/home/arvind/Videos/classification/testing.csv\",augment=True,dim=(100,100),batch_size=4))\n",
    "for image,label in train:\n",
    "    print(image.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "970f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-106293712ba3>:58: FutureWarning: rgb2grey is deprecated. It will be removed in version 0.19.Please use rgb2gray instead.\n",
      "  label=rgb2grey(np.asarray(label))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 1024, 1024])\n",
      "torch.Size([4, 3, 572, 572])\n"
     ]
    }
   ],
   "source": [
    "# Segmentation DataLoader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,img_path='/home/arvind/Videos/segmentation/Data/train',augmentation=True):\n",
    "        self.augmentation=augmentation\n",
    "        self.img=glob.glob('/home/arvind/Videos/segmentation/Data/train/image/**')\n",
    "        self.label=glob.glob('/home/arvind/Videos/segmentation/Data/train/mask/**')\n",
    "        self.aug = Compose([Rotate(limit = (5.,10.),p=0.5),OneOf([HorizontalFlip(p=0.5),VerticalFlip(p=0.5)]),\n",
    "        RandomBrightnessContrast(p=0.5,brightness_limit=0.2,contrast_limit=0.2),HueSaturationValue(p=0.3)],p=0.5,additional_targets={'mask_full':'mask'})\n",
    "\n",
    "    def augment(self,image,mask):\n",
    "        aug_img=self.aug(image=image,mask=mask)\n",
    "        return aug_img['image'],aug_img['mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __to_categorical__(self,mask):\n",
    "        \n",
    "        #Function to convert labels into categorical\n",
    "        mask_bg = np.zeros((mask.shape[0],mask.shape[1]))\n",
    "        mask_car = np.zeros((mask.shape[0],mask.shape[1]))\n",
    "         \n",
    "        mask_car[mask==1] = 1\n",
    "        mask_bg[mask==0] = 1\n",
    "        mask =np.concatenate((mask_bg[np.newaxis],mask_car[np.newaxis]),axis = 0)\n",
    "        return mask.astype(np.float32)\n",
    "    \n",
    "    def make_class_label(self,label):\n",
    "        \n",
    "        label[label==1] = 255\n",
    "        label[label==0] = 0\n",
    "        return np.uint8(label)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        images=self.img[index]\n",
    "        #label=images.replace('/image/','/mask/')\n",
    "        label=self.label[index]\n",
    "        image=Image.open(images).convert('RGB')\n",
    "        image=image.resize((572,572))\n",
    "        image=np.asarray(image)\n",
    "       \n",
    "\n",
    "        \n",
    "        label=Image.open(label).convert(\"RGB\")\n",
    "        label=label.resize((1024,1024))\n",
    "        label=rgb2grey(np.asarray(label))\n",
    "        label=self.make_class_label(label)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            image,label= self.augment(image,label)\n",
    "        label = self.__to_categorical__(label)\n",
    "        return torch.FloatTensor(image).permute(2,1,0),torch.FloatTensor(label)\n",
    "        \n",
    "train_loader= DataLoader(Train(), batch_size=4)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for (imag1, labels) in train_loader:\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(labels.shape)\n",
    "    print(imag1.shape)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89328bf5",
   "metadata": {},
   "source": [
    "# Transforms in Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "44f5dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms as t\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,path='/home/arvind/Videos/classification/test',augmentation=True,dim=(100,100),transform=None):\n",
    "        self.dim=dim\n",
    "        self.img_list=glob.glob('/home/arvind/Videos/classification/test/**/**')\n",
    "        #self.label=[i.split('/')[-2] for i in self.img_list]\n",
    "        self.dict={\"building\":0,\"forest\":1}\n",
    "        self.augmentation=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.2),\n",
    "        #GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.2)\n",
    "        ],p=0.6)\n",
    "        self.transform=transform\n",
    "    def augment(self,img):\n",
    "        aug_img=self.augmentation(image=img)\n",
    "        return aug_img['image'] \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.img_list[index]\n",
    "        labels=img.split('/')[-2]\n",
    "        img=Image.open(img)\n",
    "        img = img.resize(self.dim)\n",
    "        img=np.asarray(img)/255\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img=self.augment(img)\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "            \n",
    "        labels=self.dict[labels]\n",
    "        return torch.FloatTensor(img),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "train_transform = t.Compose([t.ToTensor(),\n",
    "                                t.Normalize((0.5, 0.5, 0.5), \n",
    "                                                     (0.5, 0.5, 0.5))])\n",
    "train=DataLoader(Train(path='/home/arvind/Videos/classification/test/**',transform=train_transform),batch_size=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f7ded",
   "metadata": {},
   "source": [
    "# Softmax and Cross-Entopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43bbe91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4223188 0.1553624 0.4223188]\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 2])\n",
    "outputs = softmax(x)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a9fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1:0.357\n",
      "loss2:0.511\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual*np.log(predicted))\n",
    "x=np.asarray([1,0,0,0])\n",
    "y=np.asarray([0.7,0.1,0.1,0.1])\n",
    "z=np.asarray([0.6,0.2,0.1,0.1]) ## loss will increase\n",
    "loss1=cross_entropy(x,y)\n",
    "loss2=cross_entropy(x,z)\n",
    "\n",
    "print(f\"loss1:{loss1:0.3f}\")\n",
    "print(f\"loss2:{loss2:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad77f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of y:  tensor([0])\n",
      "pred 1:  tensor([0])\n",
      "pred 2:  tensor([1])\n",
      "PyTorch Loss1: 0.4170\n",
      "PyTorch Loss2: 1.8406\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "y1=torch.tensor([1])\n",
    "print('value of y: ',Y)\n",
    "\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "_,pred1=torch.max(Y_pred_good,1)\n",
    "print('pred 1: ',pred1)\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "_,pred2=torch.max(Y_pred_bad,1)\n",
    "print('pred 2: ',pred2)\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7abeb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1:0.417\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual*np.log(predicted))\n",
    "x=np.asarray([1,0,0])\n",
    "y=np.asarray([2.0, 1.0, 0.1])\n",
    "y=softmax(y)\n",
    "loss1=cross_entropy(x,y)\n",
    "\n",
    "print(f\"loss1:{loss1:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb32f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred1 torch.return_types.max(\n",
      "values=tensor([3.9000, 1.2000, 2.3000, 2.2000]),\n",
      "indices=tensor([2, 0, 3, 1]))\n",
      "pred2 torch.return_types.max(\n",
      "values=tensor([5.0000, 2.0000, 1.5000, 2.2000]),\n",
      "indices=tensor([3, 3, 3, 1]))\n",
      "Batch Loss1:  1.1150\n",
      "Batch Loss2: 3.0347\n"
     ]
    }
   ],
   "source": [
    "### Loss for batch size of 4\n",
    "Y = torch.tensor([2,0,1,0])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9,0.6], # predict class 2\n",
    "    [1.2, 0.1, 0.3,0.9], # predict class 0\n",
    "    [0.3, 2.2, 0.2,2.3],\n",
    "     [0.3, 2.2, 0.1,1.9]]) # predict class 1\n",
    "pred1=torch.max(Y_pred_good,1)\n",
    "print('pred1',pred1)\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1,5.0],\n",
    "    [0.1, 0.3, 1.5,2.0],\n",
    "    [1.2, 0.2, 0.5,1.5],\n",
    "    [0.3, 2.2, 0.2,1.5]])\n",
    "pred2=torch.max(Y_pred_bad,1)\n",
    "print('pred2',pred2)\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45684c2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "609d8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc3 torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0003,  0.1476,  0.0313, -0.1012],\n",
       "        [-0.0003,  0.1484,  0.0312, -0.1008],\n",
       "        [ 0.0002,  0.1477,  0.0313, -0.1010],\n",
       "        [ 0.0010,  0.1478,  0.0307, -0.1012]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,n_class=4,n_channels=3):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=24,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=32,out_features=256)\n",
    "        self.fc2=nn.Linear(in_features=256,out_features=128)\n",
    "        self.fc3=nn.Linear(in_features=128,out_features=4)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool2(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool3(x)\n",
    "        #print('before flatting: ',x.shape)\n",
    "        x=x.view(x.size(0),x.size(1),-1)\n",
    "        #print('on doing flatting: ',x.shape)\n",
    "        x=torch.mean(x,dim=2)\n",
    "        #print('after calculating mean: ',x.shape)\n",
    "        #print('flatting',x.shape)\n",
    "        \n",
    "        x=self.fc1(x)\n",
    "        #print('after fc1',x.shape)\n",
    "        x=self.fc2(x)\n",
    "        #print('after fc2',x.shape)\n",
    "        x=self.fc3(x)\n",
    "        print('after fc3',x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model=CNN(n_class=4)\n",
    "x=torch.randn(4,3,256,256)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvind/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "###segmentation model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "x=torch.randn(4,3,1024,1024)\n",
    "model=UNet(n_class=4)\n",
    "model(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b95a7",
   "metadata": {},
   "source": [
    "## Adaptive Avarage Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b203e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056b35a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2009)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_cross_entropy(y_, y): \n",
    "    return -(y_.log()*y + (1-y)*(1-y_).log()).mean()\n",
    "\n",
    "y=torch.rand([1,1,12,8])\n",
    "y_=torch.rand([1,1,12,8])\n",
    "loss = binary_cross_entropy(y_, y)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c43b9",
   "metadata": {},
   "source": [
    "# Attention Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d78a46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 100, 100])\n",
      "torch.Size([4, 1, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1382,  0.0885,  0.2156,  ...,  0.2409,  0.1734,  0.1402],\n",
       "          [ 0.1611,  0.1879,  0.0779,  ...,  0.1017,  0.1426,  0.1705],\n",
       "          [ 0.2138,  0.1151,  0.2065,  ...,  0.0866,  0.0567,  0.2231],\n",
       "          ...,\n",
       "          [ 0.1446,  0.1508,  0.1730,  ...,  0.2398, -0.0120,  0.1381],\n",
       "          [ 0.0363,  0.1807,  0.1683,  ..., -0.0241,  0.0316,  0.2043],\n",
       "          [ 0.2821,  0.1444,  0.1310,  ...,  0.0134,  0.1966,  0.1532]]],\n",
       "\n",
       "\n",
       "        [[[-0.0187,  0.0305,  0.1288,  ...,  0.2258,  0.1170,  0.2328],\n",
       "          [ 0.0684,  0.1204,  0.1484,  ...,  0.1411,  0.1879,  0.2117],\n",
       "          [ 0.2195,  0.1852,  0.0763,  ...,  0.1434,  0.1718, -0.0779],\n",
       "          ...,\n",
       "          [ 0.0514,  0.0251,  0.2610,  ...,  0.1701,  0.1108,  0.1688],\n",
       "          [ 0.0590,  0.1551,  0.1032,  ...,  0.1173,  0.1498,  0.1180],\n",
       "          [ 0.1084,  0.1637,  0.1118,  ...,  0.1246,  0.1552,  0.2572]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2159,  0.2421,  0.0720,  ...,  0.0543,  0.1283, -0.0170],\n",
       "          [ 0.2517,  0.3363,  0.1979,  ...,  0.0046,  0.0250,  0.0489],\n",
       "          [ 0.1958,  0.3489,  0.1650,  ...,  0.1571,  0.1801,  0.0780],\n",
       "          ...,\n",
       "          [ 0.1080,  0.1711, -0.0196,  ...,  0.1268,  0.2127,  0.1989],\n",
       "          [ 0.0969,  0.0765,  0.0529,  ...,  0.2126,  0.2426, -0.0235],\n",
       "          [ 0.0474,  0.2143,  0.2465,  ...,  0.1366,  0.0864,  0.1458]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1457,  0.0565,  0.0867,  ...,  0.1757,  0.0802,  0.2964],\n",
       "          [ 0.1078,  0.0853,  0.1192,  ...,  0.1099,  0.1258,  0.2254],\n",
       "          [ 0.0687,  0.1433,  0.2445,  ...,  0.2039,  0.1471, -0.0457],\n",
       "          ...,\n",
       "          [ 0.1568,  0.2102,  0.1381,  ..., -0.0057,  0.0564,  0.1839],\n",
       "          [ 0.0664,  0.1167,  0.0790,  ...,  0.1091,  0.0595,  0.1639],\n",
       "          [ 0.0726,  0.1197,  0.1878,  ...,  0.0187, -0.0213,  0.1769]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spatial Attention\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.conv2 (x)\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9ce75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([4, 32, 100, 100])\n",
      "torch.Size([4, 1, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0262, 0.0522, 0.8230,  ..., 0.4913, 0.2711, 0.6350],\n",
       "          [0.3761, 0.1114, 0.9824,  ..., 0.4967, 0.9155, 0.7620],\n",
       "          [0.3279, 0.3883, 0.3882,  ..., 0.7728, 0.0851, 0.4713],\n",
       "          ...,\n",
       "          [0.0270, 0.4382, 0.4280,  ..., 0.9941, 0.5767, 0.0607],\n",
       "          [0.3417, 0.7304, 0.5603,  ..., 0.9621, 0.6954, 0.3495],\n",
       "          [0.4599, 0.8446, 0.0960,  ..., 0.0275, 0.3741, 0.0995]],\n",
       "\n",
       "         [[0.2884, 0.0569, 0.4078,  ..., 0.5882, 0.5662, 0.1987],\n",
       "          [0.6087, 0.6621, 0.0903,  ..., 0.7807, 0.8314, 0.7223],\n",
       "          [0.2364, 0.4533, 0.2001,  ..., 0.5693, 0.0633, 0.6276],\n",
       "          ...,\n",
       "          [0.9429, 0.6904, 0.8040,  ..., 0.7896, 0.4480, 0.2987],\n",
       "          [0.9212, 0.9352, 0.7983,  ..., 0.1570, 0.0684, 0.0560],\n",
       "          [0.9440, 0.2931, 0.1291,  ..., 0.1171, 0.1115, 0.6850]],\n",
       "\n",
       "         [[0.4524, 0.6719, 0.1480,  ..., 0.5947, 0.7498, 0.6563],\n",
       "          [0.8591, 0.5761, 0.7877,  ..., 0.6060, 0.0568, 0.7443],\n",
       "          [0.7241, 0.9386, 0.6230,  ..., 0.7046, 0.1483, 0.4096],\n",
       "          ...,\n",
       "          [0.9658, 0.5137, 0.5318,  ..., 0.2719, 0.3960, 0.2348],\n",
       "          [0.4983, 0.8760, 0.3591,  ..., 0.0307, 0.3869, 0.5271],\n",
       "          [0.8526, 0.6226, 0.2823,  ..., 0.5965, 0.8526, 0.0996]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.4442, 0.8174, 0.1411,  ..., 0.2477, 0.5125, 0.1158],\n",
       "          [0.3495, 0.0446, 0.2935,  ..., 0.4099, 0.0902, 0.7506],\n",
       "          [0.9263, 0.2637, 0.5487,  ..., 0.5670, 0.1511, 0.9889],\n",
       "          ...,\n",
       "          [0.8132, 0.1021, 0.7814,  ..., 0.4469, 0.2391, 0.1581],\n",
       "          [0.1272, 0.9510, 0.9410,  ..., 0.7289, 0.1008, 0.2225],\n",
       "          [0.4291, 0.9807, 0.9541,  ..., 0.5516, 0.8229, 0.3356]],\n",
       "\n",
       "         [[0.6979, 0.5389, 0.2628,  ..., 0.2546, 0.4466, 0.4271],\n",
       "          [0.4489, 0.5730, 0.4470,  ..., 0.7385, 0.7680, 0.2157],\n",
       "          [0.5605, 0.9801, 0.3192,  ..., 0.4556, 0.6931, 0.2688],\n",
       "          ...,\n",
       "          [0.7439, 0.8595, 0.8755,  ..., 0.4963, 0.2006, 0.0082],\n",
       "          [0.6366, 0.8386, 0.9381,  ..., 0.9706, 0.1446, 0.8994],\n",
       "          [0.6228, 0.3193, 0.4212,  ..., 0.4670, 0.1133, 0.6483]],\n",
       "\n",
       "         [[0.5409, 0.0711, 0.7738,  ..., 0.2934, 0.2047, 0.3555],\n",
       "          [0.5217, 0.5292, 0.0655,  ..., 0.3859, 0.9571, 0.3693],\n",
       "          [0.6749, 0.1287, 0.3810,  ..., 0.0536, 0.0726, 0.0895],\n",
       "          ...,\n",
       "          [0.7730, 0.2480, 0.0304,  ..., 0.3164, 0.2971, 0.4836],\n",
       "          [0.2668, 0.3119, 0.0792,  ..., 0.7670, 0.9483, 0.9536],\n",
       "          [0.4905, 0.4159, 0.9802,  ..., 0.4296, 0.2362, 0.1636]]],\n",
       "\n",
       "\n",
       "        [[[0.2885, 0.3425, 0.6757,  ..., 0.0669, 0.0820, 0.2498],\n",
       "          [0.1979, 0.8434, 0.4572,  ..., 0.7189, 0.5274, 0.7179],\n",
       "          [0.5346, 0.8013, 0.5023,  ..., 0.8045, 0.5344, 0.3468],\n",
       "          ...,\n",
       "          [0.1968, 0.8654, 0.0343,  ..., 0.0534, 0.6034, 0.1162],\n",
       "          [0.4183, 0.3966, 0.2879,  ..., 0.4365, 0.3918, 0.6882],\n",
       "          [0.9416, 0.4108, 0.7740,  ..., 0.8878, 0.8935, 0.6738]],\n",
       "\n",
       "         [[0.7054, 0.9801, 0.1005,  ..., 0.3132, 0.4650, 0.7571],\n",
       "          [0.1879, 0.0566, 0.8501,  ..., 0.1440, 0.6961, 0.6305],\n",
       "          [0.8978, 0.4098, 0.0431,  ..., 0.5740, 0.7672, 0.4359],\n",
       "          ...,\n",
       "          [0.9522, 0.7564, 0.5072,  ..., 0.6540, 0.0662, 0.4715],\n",
       "          [0.0633, 0.2684, 0.9325,  ..., 0.3585, 0.3928, 0.8213],\n",
       "          [0.4235, 0.3412, 0.1298,  ..., 0.5248, 0.8626, 0.7266]],\n",
       "\n",
       "         [[0.6662, 0.8095, 0.8099,  ..., 0.5881, 0.8330, 0.6694],\n",
       "          [0.3126, 0.2352, 0.4927,  ..., 0.5732, 0.6028, 0.3269],\n",
       "          [0.3489, 0.0142, 0.4282,  ..., 0.8920, 0.4481, 0.4988],\n",
       "          ...,\n",
       "          [0.4020, 0.6658, 0.1228,  ..., 0.8206, 0.6205, 0.5989],\n",
       "          [0.2825, 0.8635, 0.2508,  ..., 0.0123, 0.0519, 0.2882],\n",
       "          [0.6276, 0.2149, 0.2640,  ..., 0.7075, 0.5036, 0.3051]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7110, 0.6314, 0.8233,  ..., 0.9678, 0.5147, 0.9763],\n",
       "          [0.7020, 0.8506, 0.8204,  ..., 0.9128, 0.6878, 0.7093],\n",
       "          [0.5359, 0.2152, 0.1375,  ..., 0.4984, 0.2278, 0.2476],\n",
       "          ...,\n",
       "          [0.8050, 0.1958, 0.3391,  ..., 0.6265, 0.3175, 0.9449],\n",
       "          [0.0349, 0.3724, 0.4460,  ..., 0.0605, 0.8523, 0.9166],\n",
       "          [0.5271, 0.6821, 0.7525,  ..., 0.7660, 0.0487, 0.5736]],\n",
       "\n",
       "         [[0.9890, 0.9703, 0.0739,  ..., 0.0328, 0.3047, 0.0462],\n",
       "          [0.6180, 0.7275, 0.5821,  ..., 0.8851, 0.6304, 0.7262],\n",
       "          [0.3896, 0.1482, 0.7246,  ..., 0.1500, 0.1815, 0.2098],\n",
       "          ...,\n",
       "          [0.4394, 0.2678, 0.9309,  ..., 0.6334, 0.2624, 0.3467],\n",
       "          [0.5623, 0.9433, 0.4849,  ..., 0.3660, 0.6656, 0.0234],\n",
       "          [0.4994, 0.1446, 0.6525,  ..., 0.8292, 0.0410, 0.6219]],\n",
       "\n",
       "         [[0.7735, 0.4664, 0.5501,  ..., 0.5804, 0.8851, 0.3601],\n",
       "          [0.1945, 0.9392, 0.2154,  ..., 0.3362, 0.7419, 0.5826],\n",
       "          [0.4889, 0.4635, 0.4307,  ..., 0.9684, 0.9467, 0.4837],\n",
       "          ...,\n",
       "          [0.7853, 0.4879, 0.4199,  ..., 0.0627, 0.4502, 0.2485],\n",
       "          [0.0077, 0.1522, 0.8240,  ..., 0.5665, 0.6403, 0.5560],\n",
       "          [0.4752, 0.1050, 0.8243,  ..., 0.8687, 0.2064, 0.4654]]],\n",
       "\n",
       "\n",
       "        [[[0.0583, 0.3563, 0.9657,  ..., 0.2308, 0.4147, 0.2167],\n",
       "          [0.1151, 0.5513, 0.0272,  ..., 0.0350, 0.3347, 0.9817],\n",
       "          [0.4777, 0.6856, 0.8178,  ..., 0.6942, 0.4436, 0.9892],\n",
       "          ...,\n",
       "          [0.1532, 0.5849, 0.8901,  ..., 0.4721, 0.4507, 0.6657],\n",
       "          [0.2089, 0.7186, 0.7575,  ..., 0.6702, 0.7512, 0.5019],\n",
       "          [0.3218, 0.9978, 0.5455,  ..., 0.8909, 0.3220, 0.2205]],\n",
       "\n",
       "         [[0.3418, 0.2225, 0.4379,  ..., 0.8198, 0.5278, 0.4433],\n",
       "          [0.5416, 0.4667, 0.9198,  ..., 0.2573, 0.5669, 0.2935],\n",
       "          [0.5211, 0.5550, 0.6941,  ..., 0.2272, 0.7032, 0.6999],\n",
       "          ...,\n",
       "          [0.9214, 0.6686, 0.3826,  ..., 0.3004, 0.2619, 0.1479],\n",
       "          [0.1738, 0.7411, 0.4187,  ..., 0.8050, 0.5598, 0.7524],\n",
       "          [0.0229, 0.0328, 0.0200,  ..., 0.4405, 0.5618, 0.5362]],\n",
       "\n",
       "         [[0.5395, 0.1157, 0.7537,  ..., 0.4276, 0.2534, 0.4950],\n",
       "          [0.8670, 0.6990, 0.8506,  ..., 0.8472, 0.9464, 0.3653],\n",
       "          [0.8168, 0.3216, 0.7558,  ..., 0.8679, 0.9149, 0.6833],\n",
       "          ...,\n",
       "          [0.2528, 0.5655, 0.1347,  ..., 0.8742, 0.1020, 0.4900],\n",
       "          [0.3330, 0.3629, 0.0682,  ..., 0.7720, 0.8644, 0.4743],\n",
       "          [0.8249, 0.6235, 0.4332,  ..., 0.8842, 0.6561, 0.1324]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0777, 0.2430, 0.7162,  ..., 0.3059, 0.2886, 0.3431],\n",
       "          [0.9973, 0.9552, 0.5114,  ..., 0.3230, 0.4878, 0.6658],\n",
       "          [0.5594, 0.5402, 0.8867,  ..., 0.7300, 0.6848, 0.7936],\n",
       "          ...,\n",
       "          [0.1079, 0.5500, 0.2845,  ..., 0.0408, 0.3075, 0.9315],\n",
       "          [0.8099, 0.4189, 0.7981,  ..., 0.4635, 0.9811, 0.6486],\n",
       "          [0.8430, 0.5382, 0.5867,  ..., 0.3066, 0.6073, 0.4955]],\n",
       "\n",
       "         [[0.5605, 0.7006, 0.2266,  ..., 0.4414, 0.1854, 0.6927],\n",
       "          [0.9294, 0.5456, 0.4772,  ..., 0.4604, 0.5251, 0.7234],\n",
       "          [0.6079, 0.5184, 0.3423,  ..., 0.1076, 0.3973, 0.2888],\n",
       "          ...,\n",
       "          [0.1073, 0.4080, 0.7038,  ..., 0.3834, 0.2628, 0.0148],\n",
       "          [0.6904, 0.6381, 0.0141,  ..., 0.6653, 0.2549, 0.1996],\n",
       "          [0.4923, 0.3276, 0.2483,  ..., 0.6991, 0.1931, 0.1580]],\n",
       "\n",
       "         [[0.5081, 0.0324, 0.4406,  ..., 0.4677, 0.6714, 0.1821],\n",
       "          [0.1294, 0.4977, 0.4169,  ..., 0.7417, 0.5615, 0.2202],\n",
       "          [0.8959, 0.3745, 0.4188,  ..., 0.8153, 0.0722, 0.2335],\n",
       "          ...,\n",
       "          [0.7663, 0.5742, 0.0750,  ..., 0.2651, 0.2103, 0.7338],\n",
       "          [0.2519, 0.7637, 0.2665,  ..., 0.2211, 0.3723, 0.3497],\n",
       "          [0.0475, 0.3189, 0.4702,  ..., 0.0027, 0.9319, 0.7713]]],\n",
       "\n",
       "\n",
       "        [[[0.1749, 0.5558, 0.1727,  ..., 0.0721, 0.2416, 0.2575],\n",
       "          [0.7624, 0.7715, 0.1136,  ..., 0.3706, 0.5635, 0.3337],\n",
       "          [0.2396, 0.5079, 0.6395,  ..., 0.5119, 0.2188, 0.5952],\n",
       "          ...,\n",
       "          [0.3289, 0.4981, 0.2714,  ..., 0.2928, 0.6711, 0.9904],\n",
       "          [0.6742, 0.8923, 0.6009,  ..., 0.5225, 0.7293, 0.6001],\n",
       "          [0.7086, 0.4494, 0.5108,  ..., 0.9458, 0.8544, 0.9722]],\n",
       "\n",
       "         [[0.9190, 0.4387, 0.1412,  ..., 0.4370, 0.6768, 0.8117],\n",
       "          [0.0382, 0.3294, 0.9318,  ..., 0.2376, 0.7589, 0.1583],\n",
       "          [0.5118, 0.8589, 0.6123,  ..., 0.5586, 0.2752, 0.3312],\n",
       "          ...,\n",
       "          [0.2123, 0.7204, 0.4555,  ..., 0.1485, 0.5209, 0.0835],\n",
       "          [0.9133, 0.2106, 0.9254,  ..., 0.4712, 0.8266, 0.9825],\n",
       "          [0.2824, 0.2932, 0.1155,  ..., 0.1794, 0.6665, 0.9061]],\n",
       "\n",
       "         [[0.5355, 0.7170, 0.4123,  ..., 0.0851, 0.1867, 0.4219],\n",
       "          [0.2790, 0.9407, 0.3397,  ..., 0.3525, 0.4975, 0.8882],\n",
       "          [0.4233, 0.1082, 0.1746,  ..., 0.6068, 0.8439, 0.7832],\n",
       "          ...,\n",
       "          [0.2521, 0.1286, 0.6149,  ..., 0.7161, 0.9565, 0.6477],\n",
       "          [0.1824, 0.3761, 0.1802,  ..., 0.0699, 0.5893, 0.6499],\n",
       "          [0.2593, 0.6647, 0.2085,  ..., 0.2334, 0.0997, 0.6775]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7010, 0.1417, 0.0253,  ..., 0.2241, 0.3846, 0.1204],\n",
       "          [0.0914, 0.0357, 0.3339,  ..., 0.0738, 0.3975, 0.2792],\n",
       "          [0.6229, 0.1219, 0.3080,  ..., 0.8033, 0.9016, 0.4112],\n",
       "          ...,\n",
       "          [0.7245, 0.6326, 0.5173,  ..., 0.2624, 0.1842, 0.8319],\n",
       "          [0.0663, 0.9437, 0.5578,  ..., 0.8310, 0.0172, 0.0611],\n",
       "          [0.4053, 0.1694, 0.4447,  ..., 0.5649, 0.8711, 0.5145]],\n",
       "\n",
       "         [[0.9946, 0.0688, 0.9932,  ..., 0.1411, 0.4004, 0.8011],\n",
       "          [0.2958, 0.9664, 0.1100,  ..., 0.9220, 0.5016, 0.5699],\n",
       "          [0.4086, 0.1178, 0.6765,  ..., 0.4409, 0.1215, 0.6514],\n",
       "          ...,\n",
       "          [0.2299, 0.5011, 0.1878,  ..., 0.9479, 0.7163, 0.0343],\n",
       "          [0.6468, 0.2648, 0.4067,  ..., 0.6964, 0.0436, 0.5022],\n",
       "          [0.0406, 0.6285, 0.7618,  ..., 0.8760, 0.8370, 0.1056]],\n",
       "\n",
       "         [[0.5872, 0.0827, 0.1658,  ..., 0.8340, 0.6513, 0.9256],\n",
       "          [0.0405, 0.9015, 0.9090,  ..., 0.7219, 0.7133, 0.8177],\n",
       "          [0.8758, 0.3901, 0.2161,  ..., 0.3943, 0.2226, 0.2665],\n",
       "          ...,\n",
       "          [0.2289, 0.6573, 0.5814,  ..., 0.7686, 0.7822, 0.4272],\n",
       "          [0.2172, 0.7049, 0.8779,  ..., 0.3226, 0.3890, 0.7185],\n",
       "          [0.7196, 0.5786, 0.8922,  ..., 0.8927, 0.5692, 0.3235]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        print(self.in_ch)\n",
    "        self.attn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation),\n",
    "            nn.BatchNorm2d(in_ch//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation),\n",
    "            nn.BatchNorm2d(1)\n",
    "            )\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x1 = self.attn1(x)\n",
    "        print(x1.shape)\n",
    "        x1 = x1.div(math.sqrt(self.in_ch))\n",
    "        x1 = self.act(x1)\n",
    "        return x1 * x\n",
    "    \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "219eb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0525, 0.0979, 0.1569,  ..., 0.0582, 0.0247, 0.0160],\n",
       "          [0.0727, 0.1608, 0.0610,  ..., 0.1571, 0.1218, 0.1418],\n",
       "          [0.1507, 0.0386, 0.1734,  ..., 0.1465, 0.0286, 0.0477],\n",
       "          ...,\n",
       "          [0.1480, 0.1568, 0.0321,  ..., 0.0315, 0.0649, 0.0335],\n",
       "          [0.1738, 0.0994, 0.0688,  ..., 0.0802, 0.0657, 0.0310],\n",
       "          [0.0529, 0.0835, 0.1130,  ..., 0.1761, 0.1584, 0.0418]]],\n",
       "\n",
       "\n",
       "        [[[0.1763, 0.0707, 0.1292,  ..., 0.0475, 0.1614, 0.0835],\n",
       "          [0.0437, 0.0608, 0.0600,  ..., 0.1288, 0.1687, 0.0706],\n",
       "          [0.1224, 0.1491, 0.0600,  ..., 0.1608, 0.0421, 0.1761],\n",
       "          ...,\n",
       "          [0.0551, 0.0708, 0.0202,  ..., 0.0822, 0.0533, 0.1279],\n",
       "          [0.1265, 0.1765, 0.0488,  ..., 0.1384, 0.0031, 0.1202],\n",
       "          [0.0876, 0.0008, 0.0861,  ..., 0.1241, 0.1249, 0.0756]]],\n",
       "\n",
       "\n",
       "        [[[0.0253, 0.1442, 0.1468,  ..., 0.0377, 0.1401, 0.0757],\n",
       "          [0.0853, 0.1156, 0.1075,  ..., 0.0927, 0.0535, 0.0732],\n",
       "          [0.0816, 0.0781, 0.1404,  ..., 0.0458, 0.1575, 0.1125],\n",
       "          ...,\n",
       "          [0.0978, 0.0072, 0.0699,  ..., 0.1381, 0.0222, 0.1401],\n",
       "          [0.0387, 0.0832, 0.0521,  ..., 0.0437, 0.1209, 0.0474],\n",
       "          [0.1190, 0.0837, 0.1650,  ..., 0.0793, 0.1126, 0.0467]]],\n",
       "\n",
       "\n",
       "        [[[0.1444, 0.0108, 0.0325,  ..., 0.1174, 0.0546, 0.0930],\n",
       "          [0.0820, 0.1557, 0.0896,  ..., 0.0262, 0.1718, 0.0462],\n",
       "          [0.1494, 0.0458, 0.1277,  ..., 0.0226, 0.1137, 0.1222],\n",
       "          ...,\n",
       "          [0.0195, 0.0378, 0.0079,  ..., 0.0484, 0.0214, 0.1165],\n",
       "          [0.0598, 0.0500, 0.1177,  ..., 0.0100, 0.0995, 0.0458],\n",
       "          [0.1638, 0.1396, 0.0530,  ..., 0.0983, 0.0518, 0.0033]]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand([4,32,100,100])\n",
    "x1=torch.rand([4,1,100,100])\n",
    "y=x1.div(math.sqrt(32))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fec40786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([4, 1, 100, 100])\n",
    "x1=torch.rand([4, 100, 100, 100])\n",
    "l=x1*x\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8df8adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([0.4996, 0.5009, 0.5044])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([3,100,100])\n",
    "y=torch.mean(x,dim=2)\n",
    "y=torch.mean(y,dim=1)\n",
    "\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb35c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,4,9,16])\n",
    "x1=torch.tensor([1,2,3,4])\n",
    "y=x.div(x1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1186eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 50, 50])\n",
      "torch.Size([4, 1, 50, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0761, 0.0557, 0.0000],\n",
       "          [0.0754, 0.0228, 0.0540,  ..., 0.0000, 0.0423, 0.0297],\n",
       "          [0.0134, 0.0000, 0.0666,  ..., 0.0000, 0.1152, 0.0134],\n",
       "          ...,\n",
       "          [0.0017, 0.0431, 0.0304,  ..., 0.0056, 0.0134, 0.0787],\n",
       "          [0.0668, 0.0147, 0.0264,  ..., 0.0549, 0.0182, 0.0000],\n",
       "          [0.0000, 0.0534, 0.0000,  ..., 0.0570, 0.0794, 0.0180]]],\n",
       "\n",
       "\n",
       "        [[[0.0416, 0.0327, 0.0473,  ..., 0.0161, 0.0649, 0.0689],\n",
       "          [0.0236, 0.0064, 0.0248,  ..., 0.0000, 0.0000, 0.0131],\n",
       "          [0.0000, 0.0332, 0.0000,  ..., 0.0000, 0.0215, 0.0834],\n",
       "          ...,\n",
       "          [0.0556, 0.0366, 0.0503,  ..., 0.0465, 0.0120, 0.0710],\n",
       "          [0.0284, 0.0265, 0.0335,  ..., 0.0000, 0.0463, 0.0489],\n",
       "          [0.0000, 0.0000, 0.0087,  ..., 0.0000, 0.0097, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0045, 0.0000, 0.0334,  ..., 0.0878, 0.0000, 0.0459],\n",
       "          [0.1276, 0.0626, 0.0277,  ..., 0.0323, 0.0000, 0.0000],\n",
       "          [0.0136, 0.0749, 0.0000,  ..., 0.0658, 0.0338, 0.0164],\n",
       "          ...,\n",
       "          [0.0460, 0.0000, 0.0678,  ..., 0.0183, 0.0341, 0.0000],\n",
       "          [0.0185, 0.0485, 0.0723,  ..., 0.0326, 0.0000, 0.0059],\n",
       "          [0.0000, 0.0378, 0.0000,  ..., 0.0720, 0.1014, 0.0501]]],\n",
       "\n",
       "\n",
       "        [[[0.0763, 0.0142, 0.0422,  ..., 0.0615, 0.0183, 0.0000],\n",
       "          [0.0273, 0.0435, 0.0048,  ..., 0.0000, 0.0673, 0.0455],\n",
       "          [0.0140, 0.0582, 0.0054,  ..., 0.0467, 0.0295, 0.0619],\n",
       "          ...,\n",
       "          [0.0000, 0.0906, 0.0805,  ..., 0.0000, 0.0620, 0.0000],\n",
       "          [0.0000, 0.0953, 0.0326,  ..., 0.0509, 0.0000, 0.0725],\n",
       "          [0.0123, 0.0000, 0.0643,  ..., 0.0281, 0.0721, 0.0159]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True, h_max=1):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "        self.h_max = h_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) * self.h_max / 6\n",
    "    \n",
    "class scale_attention_block(nn.Module): \n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.pool=nn.AvgPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.relu=nn.ReLU()\n",
    "        self.h_sigmoid=h_sigmoid()\n",
    "    def forward(self, x):\n",
    "        x=self.pool(x)\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.h_sigmoid((self.relu(self.conv2(x))))\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e165506",
   "metadata": {},
   "outputs": [],
   "source": [
    "## channel Attention\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.conv2 (x)\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b52e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 2736, 1824])\n"
     ]
    }
   ],
   "source": [
    "### CBAM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "x=torch.rand([4,32,2736,1824])\n",
    "model=SpatialAttention(kernel_size=3)\n",
    "model1=ChannelAttention(in_planes=32)\n",
    "op=model1(x)*x\n",
    "op=model(op)*op\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bbe3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape torch.Size([4, 32, 100, 100])\n",
      "output_shape torch.Size([4, 1, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "class channel_attention(nn.Module):\n",
    "    def __init__(self,in_ch):\n",
    "        super(channel_attention,self).__init__()\n",
    "        #self.in_ch = in_ch\n",
    "        self.ca = nn.Sequential(nn.Conv2d(in_ch, in_ch//2,stride=1, kernel_size=3,bias=False,dilation=1),nn.ReLU(),\n",
    "            nn.Conv2d(in_ch//2, 1, kernel_size=3,stride=1,bias=False,dilation=1))\n",
    "            \n",
    "            \n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        print('input_shape',x.shape)\n",
    "        x=self.ca(x)\n",
    "        out=self.act(x)\n",
    "        print('output_shape',out.shape)\n",
    "        model_op=x*out\n",
    "        \n",
    "       \n",
    "       \n",
    "        return model_op\n",
    "class \n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=channel_attention(in_ch=32)\n",
    "p=model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ec1c5",
   "metadata": {},
   "source": [
    "# Loss Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "132e8222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_shape torch.Size([4, 4, 100, 100])\n",
      "inter1 shape torch.Size([4, 4, 100, 100])\n",
      "inter 2 shape torch.Size([4, 4])\n",
      "union torch.Size([4, 4, 100, 100])\n",
      "loss tensor(0.0021)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9979)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dice Loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class weighted_dice_loss(nn.Module):\n",
    "    def __init__(self, n_classes,weights = None):\n",
    "        super(weighted_dice_loss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.weights = weights\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, target, logit):\n",
    "        # logit => N x Classes x H x W\n",
    "        # target => N x H x W\n",
    "\n",
    "        N = len(logit)\n",
    "        #print(N)\n",
    "        #print('target',target.dtype)\n",
    "        #print('logit',logit.dtype)\n",
    "        pred = torch.nn.functional.softmax(logit,dim=1)\n",
    "        print('pred_shape',pred.shape)\n",
    "        #print('pred',pred.dtype)\n",
    "        #target = torch.LongTensor(target).detach().cpu()\n",
    "        #target_onehot = self.to_one_hot(target, self.n_classes)\n",
    "\n",
    "        # Numerator Product\n",
    "        inter = 2*pred * target\n",
    "        print('inter1 shape',inter.shape)\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        inter = inter.view(N, self.n_classes, -1).sum(2)\n",
    "        print('inter 2 shape',inter.shape)\n",
    "\n",
    "        # Denominator\n",
    "        union = pred + target \n",
    "        print('union',union.shape)\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        union = union.view(N, self.n_classes, -1).sum(2)\n",
    "        inter = inter * self.weights \n",
    "        union = union * self.weights\n",
    "        loss = inter / (union + 1)\n",
    "        print('loss',loss.mean())\n",
    "\n",
    "\n",
    "        # Return average loss over classes and batch\n",
    "        return 1-loss.mean()\n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "dice_loss_train = weighted_dice_loss(4,weights=weights)   \n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss2=  dice_loss_train(x,y)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e5395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "tensor(-0.0075)\n"
     ]
    }
   ],
   "source": [
    "## dice loss simplified\n",
    "class dice_loss(nn.Module):\n",
    "    def __init__(self,n_class,weights):\n",
    "        super(dice_loss,self).__init__()\n",
    "        self.weights=weights\n",
    "        self.n_class=n_class\n",
    "        \n",
    "    def forward(self,mask,output):\n",
    "        pred=torch.nn.functional.softmax(output,dim=1)\n",
    "        inter=2*mask*pred\n",
    "        inter=inter.view(inter.shape[0],inter.shape[1],-1).sum(2)\n",
    "        print(inter.shape)\n",
    "        \n",
    "        union=pred+mask\n",
    "        union=union.view(union.shape[0],union.shape[1],-1).sum(2)\n",
    "        print(union.shape)\n",
    "        inter = inter * self.weights \n",
    "        union = union * self.weights\n",
    "        loss=inter/(union+1)\n",
    "        loss=1-loss.mean()\n",
    "        print(loss)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "dice_loss_t = dice_loss(4,weights=weights)   \n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss2=  dice_loss_t(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c381e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn([4,4,100,100])\n",
    "y=x.view(4,4,-1).sum(2)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f087b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-6fc7da1ccfe0>:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y=torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones([1,4])\n",
    "print(x)\n",
    "y=torch.nn.functional.softmax(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f99a8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3941, -1.4198, -2.1953, -0.8406,  0.1629],\n",
      "        [ 1.2566,  1.4996, -0.4067,  0.3345, -0.4112],\n",
      "        [ 2.1165,  0.3435, -0.7622, -1.0368, -0.2451]], requires_grad=True)\n",
      "tensor([[-1.3633, -2.3890, -3.1645, -1.8098, -0.8063],\n",
      "        [-1.1154, -0.8725, -2.7787, -2.0375, -2.7832],\n",
      "        [-0.3097, -2.0827, -3.1883, -3.4630, -2.6713]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor(2.0749, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Negative log likelihood loss>>> To take log the probability value after softmax and add the probability value of the correct answer to the average\n",
    "### formual>>>>>>>\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3,5, requires_grad=True)\n",
    "target=torch.tensor([0,2,1])\n",
    "print(input)\n",
    "x=m(input)\n",
    "print(x)\n",
    "loss = nn.NLLLoss()\n",
    "output = loss(x, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06245ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "input torch.Size([4, 4, 10000])\n",
      "target torch.Size([4, 10000])\n",
      "torch.Size([4, 10000])\n",
      "logpt torch.Size([4, 4, 10000])\n",
      "logpt----- torch.Size([4, 4, 10000])\n",
      "tensor(1.0837)\n"
     ]
    }
   ],
   "source": [
    "### focal Loss\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=3, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = True\n",
    "\n",
    "    def forward(self, input,target):\n",
    "        \"\"\"\n",
    "        input: [N, C], float32\n",
    "        target: [N, ], int64\n",
    "        \"\"\"\n",
    "        N = input.size(0)\n",
    "        C = input.size(1)\n",
    "        print(N)\n",
    "        print(C)\n",
    "        #input = input.permute(2,3,0,1)\n",
    "        input = input.view(N,C,-1)\n",
    "        print('input',input.shape)\n",
    "        #print(input.size())\n",
    "        \n",
    "        _,target = target.max(dim=1)\n",
    "        #print(target.size())\n",
    "        target = target.view(N,-1)\n",
    "        print('target',target.shape)\n",
    "        print(target.size())\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        print('logpt',logpt.shape)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1-pt)**self.gamma * logpt\n",
    "        print('logpt-----',logpt.shape)\n",
    "        loss = F.nll_loss(logpt, target, self.weight) #negative log likelihood loss\n",
    "        return loss\n",
    "\n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "focal_loss = FocalLoss(weight=weights).cuda()\n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss=  focal_loss(x,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85709c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 10000])\n",
      "torch.Size([4, 10000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0957)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## focal loss simplified\n",
    "class focal_loss(nn.Module):\n",
    "    def __init__(self,weights,gamma=3):\n",
    "        super(focal_loss,self).__init__()\n",
    "        self.weights=weights\n",
    "        self.gamma=gamma\n",
    "        \n",
    "    def forward(self,label,output):\n",
    "        output=output.view(output.shape[0],output.shape[1],-1)\n",
    "        print(output.shape)\n",
    "        log=torch.nn.functional.log_softmax(output,dim=1)\n",
    "        pt=torch.exp(log)\n",
    "        logpt=(1-pt)**self.gamma*log\n",
    "        \n",
    "        _,label=label.max(dim=1)\n",
    "        label=label.view(label.shape[0],-1)\n",
    "        print(label.shape)\n",
    "        \n",
    "        loss = F.nll_loss(logpt, label, self.weights) #negative log likelihood loss\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "focal_loss = focal_loss(weights=weights).cuda()\n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "focal_loss(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085078b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## boundary loss\n",
    "def one_hot(label, n_classes, requires_grad=True):\n",
    "    \"\"\"Return One Hot Label\"\"\"\n",
    "    device = label.device\n",
    "    one_hot_label = torch.eye(\n",
    "        n_classes, device=device, requires_grad=requires_grad)[label]\n",
    "    one_hot_label = one_hot_label.transpose(1, 3).transpose(2, 3)\n",
    "\n",
    "    return one_hot_label\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"Boundary Loss proposed in:\n",
    "    Alexey Bokhovkin et al., Boundary Loss for Remote Sensing Imagery Semantic Segmentation\n",
    "    https://arxiv.org/abs/1905.07852\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta0=3, theta=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta0 = theta0\n",
    "        self.theta = theta\n",
    "\n",
    "    @staticmethod\n",
    "    def to_one_hot(tensor, n_classes):\n",
    "        #tensor = torch.FloatTensor(tensor)\n",
    "        n, h, w = tensor.size()\n",
    "        # print('N H W',n,h,w)\n",
    "        zeros = torch.zeros(n, n_classes, h, w)\n",
    "        #zeros = torch.cuda.FloatTensor(tensor.size(0),n_classes,tensor.size(1),tensor.size(2)).zero_()\n",
    "        #view_tensor = tensor.view(n, 1, h, w)\n",
    "        view_tensor = torch.reshape(tensor,(n,-1))\n",
    "        #print(\"tensor reshape\", tensor.dtype)\n",
    "        ones = torch.ones(tensor.size())\n",
    "        one_hot = zeros.scatter_(1, tensor, ones)\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        \n",
    "\n",
    "        n, c, _, _ = pred.shape\n",
    "\n",
    "        # softmax so that predicted map can be distributed in [0, 1]\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "        # one-hot vector of ground truth\n",
    "        # gt = torch.LongTensor(gt).detach().cpu()\n",
    "        # gt = torch.LongTensor(gt.long().detach().cpu())\n",
    "        # one_hot_gt = self.to_one_hot(gt, c)\n",
    "        one_hot_gt = gt\n",
    "\n",
    "        # boundary map\n",
    "        gt_b = F.max_pool2d(\n",
    "            1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        gt_b -= 1 - one_hot_gt\n",
    "\n",
    "        pred_b = F.max_pool2d(\n",
    "            1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        pred_b -= 1 - pred\n",
    "\n",
    "        # extended boundary map\n",
    "        gt_b_ext = F.max_pool2d(\n",
    "            gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        pred_b_ext = F.max_pool2d(\n",
    "            pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        # reshape\n",
    "        gt_b = gt_b.view(n, c, -1)\n",
    "        pred_b = pred_b.view(n, c, -1)\n",
    "        gt_b_ext = gt_b_ext.view(n, c, -1)\n",
    "        pred_b_ext = pred_b_ext.view(n, c, -1)\n",
    "\n",
    "        # Precision, Recall\n",
    "        P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
    "        R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
    "\n",
    "        # Boundary F1 Score\n",
    "        BF1 = 2 * P * R / (P + R + 1e-7)\n",
    "\n",
    "        # summing BF1 Score for each class and average over mini-batch\n",
    "        loss = torch.mean(1 - BF1)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d1be028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/home/arvind/Documents/gauge_200_backtest_results/cumulative_grade_5jan_all_cls.csv')\n",
    "df=df[['imei','manual_grade']]\n",
    "df1=df.drop_duplicates(subset=['imei'])\n",
    "df1.to_csv('/home/arvind/Documents/gauge_200_backtest_results/used_manual_grade_gauge_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2ff6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cumulative_grade_5jan_all_cls.csv')\n",
    "#df.head()\n",
    "df['front_grade_old']=df['front_grade']\n",
    "df=df[['imei','asset_id','front_grade_old']]\n",
    "df1=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cummulative_all_side_sourabh_front_model.csv')\n",
    "df1['front_grade_new']=df1['front_grade']\n",
    "df1=df1[['imei','asset_id','front_grade_new']]\n",
    "df2=df.merge(df1,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55f3152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')\n",
    "df1=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cummulative_all_side_sourabh_front_model_1.csv')\n",
    "df1['front_grade_new_1']=df1['front_grade']\n",
    "df1=df1[['imei','asset_id','front_grade_new_1']]\n",
    "df2=df.merge(df1,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b010945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/cumulative_grade_5jan_all_cls.xlsx',sheet_name='cumulative_grade_5jan_all_cls')\n",
    "#df.head()\n",
    "df['back_grade_old']=df['back_grade']\n",
    "df['pred_cumulative_grade_old']=df['pred_cumulative_grade']\n",
    "df=df[['imei','asset_id','back_grade_old','pred_cumulative_grade_old']]\n",
    "df1=pd.read_excel('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/cummulative_all_side_sourabh_back_model_val_acc_2.xlsx',sheet_name='cummulative_all_side_sourabh_back_model')\n",
    "df1['back_grade_new']=df1['back_grade']\n",
    "df1['pred_cumulative_grade_new']=df1['pred_cumulative_grade']\n",
    "df1=df1[['imei','asset_id','back_grade_new','pred_cumulative_grade_new','manual_grade']]\n",
    "df2=df1.merge(df,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/back_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d5067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-b461ac9e692f>:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  p=torch.nn.init.xavier_uniform(w)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8128, -0.1080,  0.6075,  0.7040,  0.2738],\n",
       "        [-0.7531,  0.1176,  0.8206, -0.1864, -0.8137],\n",
       "        [-0.4104, -0.2329,  0.1000, -0.8528,  0.1989]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "w = torch.empty(3, 5)\n",
    "p=torch.nn.init.xavier_uniform(w)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd59223",
   "metadata": {},
   "source": [
    "# Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dffe862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1\n",
      "conv1.bias\n",
      "conv1\n",
      "conv2.weight\n",
      "conv2\n",
      "conv2.bias\n",
      "conv2\n",
      "conv3.weight\n",
      "conv3\n",
      "conv3.bias\n",
      "conv3\n",
      "fc1.weight\n",
      "fc1\n",
      "fc1.bias\n",
      "fc1\n",
      "fc2.weight\n",
      "fc2\n",
      "fc2.bias\n",
      "fc2\n",
      "fc3.weight\n",
      "fc3\n",
      "fc3.bias\n",
      "fc3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,n_class=4,n_channels=3):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=24,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=32,out_features=256)\n",
    "        self.fc2=nn.Linear(in_features=256,out_features=128)\n",
    "        self.fc3=nn.Linear(in_features=128,out_features=4)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool2(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool3(x)\n",
    "        #print('before flatting: ',x.shape)\n",
    "        x=x.view(x.size(0),x.size(1),-1)\n",
    "        #print('on doing flatting: ',x.shape)\n",
    "        x=torch.mean(x,dim=2)\n",
    "        #print('after calculating mean: ',x.shape)\n",
    "        #print('flatting',x.shape)\n",
    "        \n",
    "        x=self.fc1(x)\n",
    "        #print('after fc1',x.shape)\n",
    "        x=self.fc2(x)\n",
    "        #print('after fc2',x.shape)\n",
    "        x=self.fc3(x)\n",
    "        #print('after fc3',x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model=CNN(n_class=4)\n",
    "x=torch.randn(4,3,256,256)\n",
    "model(x)\n",
    "#*****************************\n",
    " #model_dict = model.state_dict()\n",
    " #print(model_dict)\n",
    "\n",
    "#**************************\n",
    "\n",
    " #print(model.state_dict().keys())\n",
    " #print(model.state_dict().values())\n",
    " #print(model.state_dict().items())\n",
    "#*****************************\n",
    "#for param in model.parameters():\n",
    "#  print(param.data)\n",
    "\n",
    "#***********************\n",
    "\n",
    "#for num,i in enumerate(model_dict):\n",
    "#        print(i)\n",
    "#*************************\n",
    "#pretrained_dict = {k: v for k, v in model.state_dict().items() if k in model_dict}\n",
    "#pretrained_dict\n",
    "#********************************\n",
    "\n",
    "### freezing a list of layers\n",
    "convs = ['conv1','conv2']\n",
    "freezed=[]\n",
    "for i, layer in enumerate(model.state_dict()):\n",
    "    print(layer)\n",
    "    layers_name=layer.split('.')[0]\n",
    "    print(layers_name)\n",
    "    if layers_name in convs:\n",
    "        freezed.append(layers_name)\n",
    "#print(freezed) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed69c9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Linear(in_features=32, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=4, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, child in model.named_children():\n",
    "    #print(name)\n",
    "    print(child)\n",
    "    for param in child.parameters():\n",
    "        if name in freezed:\n",
    "            param.requires_grad = False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132d011",
   "metadata": {},
   "source": [
    "# Image Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3c4b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352756638.png\n",
      "/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352855202.png\n",
      "/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352656159.png\n",
      "/home/arvind/Music/arv/full_img/111111111116_BRIGMIAM00061650526082959.png\n",
      "/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352554267.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "def crop(infile,height,width):\n",
    "    im = Image.open(infile)\n",
    "    imgwidth, imgheight = im.size\n",
    "    for i in range(imgheight//height):\n",
    "        for j in range(imgwidth//width):\n",
    "            box = (j*width, i*height, (j+1)*width, (i+1)*height)\n",
    "            a = im.crop(box)\n",
    "            \n",
    "            \n",
    "\n",
    "path='/home/arvind/Music/arv/full_img/**'\n",
    "for img in glob.glob(path):\n",
    "    print(img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "110c8b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352756638.png', '/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352855202.png', '/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352656159.png', '/home/arvind/Music/arv/full_img/111111111116_BRIGMIAM00061650526082959.png', '/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352554267.png']\n"
     ]
    }
   ],
   "source": [
    "## MAIN\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "imgdir = \"/home/arvind/Music/arv/full_img\"\n",
    "filelist = [f for f in glob.glob(imgdir + \"/**.png\", recursive=True)]\n",
    "print(filelist)\n",
    "savedir = \"/home/arvind/Music/arv/patch/\"\n",
    "\n",
    "start_pos = start_x, start_y = (0, 0)\n",
    "cropped_image_size = w, h = (512, 512)\n",
    "\n",
    "for file in filelist:\n",
    "    img = Image.open(file)\n",
    "    width, height = img.size\n",
    "\n",
    "    frame_num = 1\n",
    "    for col_i in range(0, width, w):\n",
    "        for row_i in range(0, height, h):\n",
    "            crop = img.crop((col_i, row_i, col_i + w, row_i + h))\n",
    "            name = os.path.basename(file)\n",
    "            name = os.path.splitext(name)[0]\n",
    "            save_to= os.path.join(savedir, name+\"_{:03}.png\")\n",
    "            crop.save(save_to.format(frame_num))\n",
    "            frame_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33b6e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111111111110_BRIGMIAM00061650352756638.png\n",
      "111111111110_BRIGMIAM00061650352855202.png\n",
      "111111111110_BRIGMIAM00061650352656159.png\n",
      "111111111116_BRIGMIAM00061650526082959.png\n",
      "111111111110_BRIGMIAM00061650352554267.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "def prediction_patches(img,patch_size=[512,512]):\n",
    "        img = np.asarray(img).astype('float32')\n",
    "        #print(img.shape)\n",
    "        #assert(img.shape[0]%patch_size[0]==0 and img.shape[1]%patch_size[1]==0)\n",
    "        h_patch = int(img.shape[0]/patch_size[0])\n",
    "        w_patch = int(img.shape[1]/patch_size[1])\n",
    "        patches = []\n",
    "\n",
    "       \n",
    "        no = 0\n",
    "        x = 0\n",
    "        for i in range(h_patch):\n",
    "            y = 0 \n",
    "            for j in range(w_patch):\n",
    "                \n",
    "                \n",
    "                patch = img[x:(((i+1)*patch_size[0])),y:(((j+1)*patch_size[1])),:]\n",
    "                \n",
    "                \n",
    "                y = ((j+1)*patch_size[1])\n",
    "                \n",
    "                no+=1\n",
    "            patches.append(patch)\n",
    "            \n",
    "            x = ((i+1)*patch_size[0])\n",
    "        \n",
    "        return patch\n",
    "\n",
    "save_path='/home/arvind/Music/arv/patch/'    \n",
    "path='/home/arvind/Music/arv/full_img/**'\n",
    "for img in glob.glob(path):\n",
    "    a=Image.open(img)\n",
    "    a=prediction_patches(a,patch_size=[512,512])\n",
    "    name=img.split('/')[-1]\n",
    "    print(name)\n",
    "    z = random.randint(0,100)\n",
    "    cv2.imwrite(save_path+'/sss'+name+'_'+str(z)+'.png',a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a65b67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111111111110_BRIGMIAM00061650352756638.png\n",
      "111111111110_BRIGMIAM00061650352855202.png\n",
      "111111111110_BRIGMIAM00061650352656159.png\n",
      "111111111116_BRIGMIAM00061650526082959.png\n",
      "111111111110_BRIGMIAM00061650352554267.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "patch_size=(1024,1024)\n",
    "save_path='/home/arvind/Music/arv/patch/'    \n",
    "path='/home/arvind/Music/arv/full_img/**'\n",
    "for file in glob.glob(path):\n",
    "    \n",
    "    img=Image.open(file)\n",
    "    img=np.array(img)\n",
    "    \n",
    "    name=file.split('/')[-1]\n",
    "    print(name)\n",
    "    \n",
    "    h_patch = int(img.shape[0]/patch_size[0])\n",
    "    w_patch = int(img.shape[1]/patch_size[1])\n",
    "    patches = []\n",
    "    \n",
    "    no = 0\n",
    "    x = 0\n",
    "    for i in range(h_patch):\n",
    "        y = 0 \n",
    "        for j in range(w_patch):\n",
    "            \n",
    "            \n",
    "            patch = img[x:(((i+1)*patch_size[0])),y:(((j+1)*patch_size[1])),:]\n",
    "            \n",
    "            cv2.imwrite(save_path+'/sss'+name+'_'+str(i)+\"_\"+str(j)+'.png',patch)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02c24fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111111111110_BRIGMIAM00061650352756638.png\n",
      "111111111110_BRIGMIAM00061650352855202.png\n",
      "111111111110_BRIGMIAM00061650352656159.png\n",
      "111111111116_BRIGMIAM00061650526082959.png\n",
      "111111111110_BRIGMIAM00061650352554267.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "patch_size=(1024,1024)\n",
    "save_path='/home/arvind/Music/arv/patch/'    \n",
    "path='/home/arvind/Music/arv/full_img/**'\n",
    "for file in glob.glob(path):\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    hMod = h % patch_size[0]\n",
    "    wMod = w % patch_size[1]\n",
    "    hPad = 0\n",
    "    wPad = 0\n",
    "    if(hMod!=0 or wMod!=0):\n",
    "        hPad = patch_size[0]-hMod\n",
    "        wPad = patch_size[1]-wMod\n",
    "    img=Image.open(file)\n",
    "    img=np.array(img)\n",
    "    img = np.pad(img, ((0, hPad),(0,wPad),(0,0)), 'constant')\n",
    "    \n",
    "    name=file.split('/')[-1]\n",
    "    print(name)\n",
    "    \n",
    "    h_patch = int(img.shape[0]/patch_size[0])\n",
    "    w_patch = int(img.shape[1]/patch_size[1])\n",
    "    patches = []\n",
    "    \n",
    "    no = 0\n",
    "    x = 0\n",
    "    for i in range(h_patch):\n",
    "        y = 0 \n",
    "        for j in range(w_patch):\n",
    "            \n",
    "            \n",
    "            patch = img[x:(((i+1)*patch_size[0])),y:(((j+1)*patch_size[1])),:]\n",
    "            \n",
    "            cv2.imwrite(save_path+'/sss'+name+'_'+str(i)+\"_\"+str(j)+'.png',patch)\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d32bdb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-2e8fb5342c96>:15: FutureWarning: rgb2grey is deprecated. It will be removed in version 0.19.Please use rgb2gray instead.\n",
      "  img = color.rgb2grey(img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.     0.0721 0.7154 1.    ]\n",
      "[0.     0.0721 0.7154 0.7875 1.    ]\n",
      "[0.     0.0721 0.7154]\n",
      "[0.     0.0721 0.7154 1.    ]\n",
      "[0.     0.0721 0.7154 1.    ]\n",
      "[0.     0.0721 0.7154 1.    ]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage import io,color\n",
    "sc=[]\n",
    "path='/home/arvind/Music/arv/asdf/'\n",
    "for file in glob.glob(path+'/**'):\n",
    "    #print(file)\n",
    "    #print(file)\n",
    "    img=cv2.imread(file)\n",
    "    #print(file)\n",
    "    img = color.rgb2grey(img)\n",
    "    print(np.unique(img))\n",
    "    if img.any()==0.7875:\n",
    "        print(file)\n",
    "        sc.append(file)\n",
    "print(len(sc))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42f44ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(3, 5, max_norm=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, d, m = 3, 5, 7\n",
    "embedding = nn.Embedding(n, d, max_norm=True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8c006b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [ 0.4110, -1.2937, -0.5758,  0.6235,  0.5376, -0.1804, -0.7206,\n",
       "           0.0405],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000],\n",
       "         [-0.4088, -0.8718, -1.1414,  0.0476, -0.3927,  0.8642,  0.2758,\n",
       "           1.1535]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(6, 8, padding_idx=0)\n",
    "input = torch.LongTensor([[0,2,0,5]])\n",
    "\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8e4d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import patchify\n",
    "image=cv2.imread('/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352554267.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ec6dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 4531, 3)\n",
      "(4096, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "\n",
    "img = cv2.imread('/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352554267.png')\n",
    "save_path='/home/arvind/Music/arv/patches/'\n",
    "print(img.shape)\n",
    "img=cv2.resize(img,(2048,4096))\n",
    "print(img.shape)\n",
    "patches_img = patchify(img, (1024, 1024,3), step=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10c55aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 4531, 3)\n",
      "(2048, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"/home/arvind/Music/arv/full_img/111111111110_BRIGMIAM00061650352554267.png\")\n",
    "print(img.shape)\n",
    "img=cv2.resize(img,(4096,2048))\n",
    "print(img.shape)\n",
    "patches_img = patchify(img, (512,512,3), step=512)\n",
    "\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        cv2.imwrite('/home/arvind/Music/arv/patches/'+'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch_img)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4081b75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "351713084874885_0ATT0RLO00011571339544843_back_12\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351823092779602_0ATT0RLO00011572313457977\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351713084939209_0ATT0RLO00011571330438108\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351810070381121_0ATT0RLO00011571427474570\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "100001000010000_0ATT0RLO00011571843345709\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351713084874885_0ATT0RLO00011571339544843_back_12\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351823092779602_0ATT0RLO00011572313457977\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351713084939209_0ATT0RLO00011571330438108\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351810070381121_0ATT0RLO00011571427474570\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "100001000010000_0ATT0RLO00011571843345709\n",
      "(1024, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "#final\n",
    "import cv2\n",
    "import \n",
    "path='/home/arvind/Music/arv/path_creation/full_img'\n",
    "save_path_patch=''\n",
    "for file in glob.glob(path+'/**/**'):\n",
    "    #print(file)\n",
    "    img=cv2.imread(file)\n",
    "    #print(img.shape)\n",
    "    img=cv2.resize(img,(2048,1024))\n",
    "    image=file.split('/')[-1].split('.')[0]\n",
    "    Folder=file.split('/')[-2]\n",
    "    print(Folder)\n",
    "    print(image)\n",
    "    print(img.shape)\n",
    "    \n",
    "    patches_img = patchify(img, (512,512,3), step=512)\n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "            cv2.imwrite(save_path+\"/\"+str(Folder)+'/'+image+ '_'+ str(i)+str(j)+'.png', single_patch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a289e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "351713084874885_0ATT0RLO00011571339544843_back_12\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351823092779602_0ATT0RLO00011572313457977\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351713084939209_0ATT0RLO00011571330438108\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "351810070381121_0ATT0RLO00011571427474570\n",
      "(1024, 2048, 3)\n",
      "5000\n",
      "100001000010000_0ATT0RLO00011571843345709\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351713084874885_0ATT0RLO00011571339544843_back_12\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351823092779602_0ATT0RLO00011572313457977\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351713084939209_0ATT0RLO00011571330438108\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "351810070381121_0ATT0RLO00011571427474570\n",
      "(1024, 2048, 3)\n",
      "Labels\n",
      "100001000010000_0ATT0RLO00011571843345709\n",
      "(1024, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from patchify import patchify\n",
    "list_of_folders=['1000','5000','13000_1','13000_2','300000','Labels']\n",
    "path='/home/arvind/Music/arv/path_creation/full_img'\n",
    "save_path_patch='/home/arvind/Music/arv/path_creation/Patch/'\n",
    "for file in glob.glob(path+'/**/**'):\n",
    "    #print(file)\n",
    "    img=cv2.imread(file)\n",
    "    #print(img.shape)\n",
    "    img=cv2.resize(img,(2048,1024))\n",
    "    image=file.split('/')[-1].split('.')[0]\n",
    "    Folder=file.split('/')[-2]\n",
    "    print(Folder)\n",
    "    print(image)\n",
    "    print(img.shape)\n",
    "    os.makedirs(save_path_patch+Folder,exist_ok=True)\n",
    "    patches_img = patchify(img, (512,512,3), step=512)\n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "            cv2.imwrite(save_path_patch+\"/\"+str(Folder)+'/'+image+ '_'+ str(i)+str(j)+'.png', single_patch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0181d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from patchify import patchify\n",
    "list_of_folders=['1000','5000','13000_1','13000_2','300000','Labels']\n",
    "path='/home/arvind/Music/arv/path_creation/full_img'\n",
    "save_path_patch='/home/arvind/Music/arv/path_creation/Patch/'\n",
    "for file in glob.glob(path+'/**/**'):\n",
    "    #print(file)\n",
    "    img=cv2.imread(file)\n",
    "    #print(img.shape)\n",
    "    img=cv2.resize(img,(2048,1024))\n",
    "    image=file.split('/')[-1].split('.')[0]\n",
    "    Folder=file.split('/')[-2]\n",
    "    print(Folder)\n",
    "    print(image)\n",
    "    print(img.shape)\n",
    "    os.makedirs(save_path_patch+Folder,exist_ok=True)\n",
    "    patches_img = patchify(img, (512,512,3), step=512)\n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "            cv2.imwrite(save_path_patch+\"/\"+str(Folder)+'/'+image+ '_'+ str(i)+str(j)+'.png', single_patch_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739f026",
   "metadata": {},
   "source": [
    "# Vision Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd3eb4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 512, 512])\n",
      "torch.Size([4, 768, 32, 32])\n",
      "torch.Size([4, 768, 1024])\n",
      "torch.Size([4, 1024, 768])\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_size, patch_size, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "\n",
    "        self.proj = nn.Conv2d(\n",
    "                in_chans,\n",
    "                embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.proj(x)\n",
    "        print(x.shape)\n",
    "        x = x.flatten(2)\n",
    "        print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        print(x.shape)\n",
    "\n",
    "        return x\n",
    "    \n",
    "x=torch.randn([4,3,512,512])\n",
    "model=PatchEmbed(img_size=512,patch_size=16,in_chans=3,embed_dim=768)\n",
    "p=model(x)\n",
    "print(model.n_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8c261f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.rand([4,3,100,100])\n",
    "t=z.flatten(0)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a240c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eaee4d7613fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m577\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-eaee4d7613fc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "   \n",
    "    def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('pass')\n",
    "        n_samples, n_tokens, dim = x.shape\n",
    "\n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "\n",
    "        qkv = self.qkv(x)  # (n_samples, n_patches + 1, 3 * dim)\n",
    "        qkv = qkv.reshape(\n",
    "                n_samples, n_tokens, 3, self.n_heads, self.head_dim\n",
    "        )  # (n_smaples, n_patches + 1, 3, n_heads, head_dim)\n",
    "        qkv = qkv.permute(\n",
    "                2, 0, 3, 1, 4\n",
    "        )  # (3, n_samples, n_heads, n_patches + 1, head_dim)\n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        k_t = k.transpose(-2, -1)  # (n_samples, n_heads, head_dim, n_patches + 1)\n",
    "        dp = (\n",
    "           q @ k_t\n",
    "        ) * self.scale # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "        attn = dp.softmax(dim=-1)  # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        weighted_avg = attn @ v  # (n_samples, n_heads, n_patches +1, head_dim)\n",
    "        weighted_avg = weighted_avg.transpose(\n",
    "                1, 2\n",
    "        )  # (n_samples, n_patches + 1, n_heads, head_dim)\n",
    "        weighted_avg = weighted_avg.flatten(2)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "        x = self.proj(weighted_avg)  # (n_samples, n_patches + 1, dim)\n",
    "        x = self.proj_drop(x)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "        return x\n",
    "\n",
    "x=torch.tensor([4, 577, 768])\n",
    "model=Attention(dim=768, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bffa8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=torch.tensor([1,768])\n",
    "y=nn.Linear(100,200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55e1439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 1])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([1,768,1])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "107fece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "shape of input in attention block torch.Size([4, 577, 768])\n",
      "qkv torch.Size([4, 577, 2304])\n",
      "q torch.Size([4, 8, 577, 96])\n",
      "k torch.Size([4, 8, 577, 96])\n",
      "v torch.Size([4, 8, 577, 96])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "   \n",
    "    def __init__(self, img_size, patch_size, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "\n",
    "        self.proj = nn.Conv2d(\n",
    "                in_chans,\n",
    "                embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.proj(\n",
    "                x\n",
    "            )  # (n_samples, embed_dim, n_patches ** 0.5, n_patches ** 0.5)\n",
    "        x = x.flatten(2)  # (n_samples, embed_dim, n_patches)\n",
    "        x = x.transpose(1, 2)  # (n_samples, n_patches, embed_dim)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "   \n",
    "    def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('shape of input in attention block',x.shape)\n",
    "        n_samples, n_tokens, dim = x.shape\n",
    "\n",
    "        if dim != self.dim:\n",
    "            raise ValueError\n",
    "\n",
    "        qkv = self.qkv(x)  # (n_samples, n_patches + 1, 3 * dim)\n",
    "        print('qkv',qkv.shape)\n",
    "        qkv = qkv.reshape(\n",
    "                n_samples, n_tokens, 3, self.n_heads, self.head_dim\n",
    "        )  # (n_smaples, n_patches + 1, 3, n_heads, head_dim)\n",
    "        qkv = qkv.permute(\n",
    "                2, 0, 3, 1, 4\n",
    "        )  # (3, n_samples, n_heads, n_patches + 1, head_dim)\n",
    "\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        print('q',q.shape)\n",
    "        print('k',k.shape)\n",
    "        print('v',v.shape)\n",
    "        k_t = k.transpose(-2, -1)  # (n_samples, n_heads, head_dim, n_patches + 1)\n",
    "        dp = (\n",
    "           q @ k_t\n",
    "        ) * self.scale # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "        attn = dp.softmax(dim=-1)  # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        weighted_avg = attn @ v  # (n_samples, n_heads, n_patches +1, head_dim)\n",
    "        weighted_avg = weighted_avg.transpose(\n",
    "                1, 2\n",
    "        )  # (n_samples, n_patches + 1, n_heads, head_dim)\n",
    "        weighted_avg = weighted_avg.flatten(2)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "        x = self.proj(weighted_avg)  # (n_samples, n_patches + 1, dim)\n",
    "        x = self.proj_drop(x)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_features, out_features, p=0.):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.fc1(\n",
    "                x\n",
    "        ) # (n_samples, n_patches + 1, hidden_features)\n",
    "        x = self.act(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "        x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "        x = self.fc2(x)  # (n_samples, n_patches + 1, out_features)\n",
    "        x = self.drop(x)  # (n_samples, n_patches + 1, out_features)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "   \n",
    "    def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.attn = Attention(\n",
    "                dim,\n",
    "                n_heads=n_heads,\n",
    "                qkv_bias=qkv_bias,\n",
    "                attn_p=attn_p,\n",
    "                proj_p=p\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "        hidden_features = int(dim * mlp_ratio)\n",
    "        self.mlp = MLP(\n",
    "                in_features=dim,\n",
    "                hidden_features=hidden_features,\n",
    "                out_features=dim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "   \n",
    "    def __init__(\n",
    "            self,\n",
    "            img_size=512,\n",
    "            patch_size=16,\n",
    "            in_chans=3,\n",
    "            n_classes=2,\n",
    "            embed_dim=768,\n",
    "            depth=12,\n",
    "            n_heads=12,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=True,\n",
    "            p=0.,\n",
    "            attn_p=0.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embed = PatchEmbed(\n",
    "                img_size=img_size,\n",
    "                patch_size=patch_size,\n",
    "                in_chans=in_chans,\n",
    "                embed_dim=embed_dim,\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(\n",
    "                torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
    "        )\n",
    "        self.pos_drop = nn.Dropout(p=p)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    dim=embed_dim,\n",
    "                    n_heads=n_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    p=p,\n",
    "                    attn_p=attn_p,\n",
    "                )\n",
    "                for _ in range(depth)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.head = nn.Linear(embed_dim, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "     \n",
    "        n_samples = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_token = self.cls_token.expand(\n",
    "                n_samples, -1, -1\n",
    "        )  # (n_samples, 1, embed_dim)\n",
    "        x = torch.cat((cls_token, x), dim=1)  # (n_samples, 1 + n_patches, embed_dim)\n",
    "        x = x + self.pos_embed  # (n_samples, 1 + n_patches, embed_dim)\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        cls_token_final = x[:, 0]  # just the CLS token\n",
    "        x = self.head(cls_token_final)\n",
    "        print(x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "custom_config = {\n",
    "        \"img_size\": 384,\n",
    "        \"in_chans\": 3,\n",
    "        \"patch_size\": 16,\n",
    "        \"embed_dim\": 768,\n",
    "        \"depth\": 8,\n",
    "        \"n_heads\": 8,\n",
    "        \"qkv_bias\": True,\n",
    "        \"mlp_ratio\": 4,\n",
    "        \"n_classes\":4\n",
    "}\n",
    "\n",
    "x=torch.randn([4,3,384,384])\n",
    "model_custom = VisionTransformer(**custom_config)\n",
    "m=model_custom(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53c369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "N, C, H, W = 20, 5, 10, 10\n",
    "input = torch.randn(N, C, H, W)\n",
    "\n",
    "layer_norm = nn.LayerNorm([C, H, W])\n",
    "output = layer_norm(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1fb16",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d48b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3ac17fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n",
      "torch.Size([20, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-8d6b9b471255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I;16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     img = torch.from_numpy(\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"category\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             warnings.warn(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure(figsize=(20, 20))\n",
    "for image, label in train_dataloader:\n",
    "    for i ,img in enumerate(image):\n",
    "        img=(img.permute(2,1,0).numpy()*255).astype(np.uint8)\n",
    "        print(img.shape)\n",
    "        fig2.add_subplot(4, 5, i+1 )\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "138a1ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([100, 28, 28])\n",
      "h0 shape torch.Size([2, 100, 128])\n",
      "shape of out torch.Size([100, 128])\n",
      "output shape torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.sltm = nn.lstm(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('input',x.shape)\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        print('h0 shape',h0.shape)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, h0)\n",
    "        #print('shape of RNN output',out.shape)\n",
    "        # or:\n",
    "        #out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        print('shape of out',out.shape)\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        print('output shape',out.shape)\n",
    "        return out\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "images=torch.randn([100,1,28,28])\n",
    "images = images.reshape(-1, sequence_length, input_size)\n",
    "p=model(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2d236b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 2213, 3)\n",
      "(1280, 2304, 3)\n",
      "4\n",
      "8\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "import random\n",
    "fig2 = plt.figure(figsize=(20, 20))\n",
    "\n",
    "from PIL import Image\n",
    "def pad_input(input_img,patch_size=[512,512]):\n",
    "        h = input_img.shape[0]\n",
    "        w = input_img.shape[1]\n",
    "        hMod = h % patch_size[0]\n",
    "        wMod = w % patch_size[1]\n",
    "        hPad = 0\n",
    "        wPad = 0\n",
    "        if(hMod!=0 or wMod!=0):\n",
    "            hPad = patch_size[0]-hMod\n",
    "            wPad = patch_size[1]-wMod\n",
    "        output = np.pad(input_img, ((0, hPad),(0,wPad),(0,0)), 'constant')\n",
    "        return(output, hPad,wPad )\n",
    "    \n",
    "def prediction_patches(img,patch_size=[512,512],stride=256):\n",
    "        #img = np.asarray(img).astype('float32')\n",
    "        #print(img.shape)\n",
    "        assert((img.shape[0]-stride)%stride==0 and (img.shape[1]-stride)%stride==0)\n",
    "        h_patch = int((img.shape[0]-stride)/stride)\n",
    "        w_patch = int((img.shape[1]-stride)/stride)\n",
    "        print(h_patch)\n",
    "        print(w_patch)\n",
    "        patches = []\n",
    "\n",
    "       \n",
    "        no = 0\n",
    "        x = 0\n",
    "        for i in range(h_patch):\n",
    "            \n",
    "            y = 0 \n",
    "            for j in range(w_patch):\n",
    "                if i==0 and j==0:\n",
    "   \n",
    "                    patch = img[x:(((i+1)*patch_size[0]))-(i)*stride,y:(((j+1)*patch_size[1]))-(j)*stride,:]\n",
    "                \n",
    "                \n",
    "                #print(patch.shape)\n",
    "                \n",
    "                y = ((j+1)*patch_size[1])-(j+1)*stride\n",
    "                \n",
    "                no+=1\n",
    "                patches.append(patch)\n",
    "            x = ((i+1)*patch_size[0])-(i+1)*stride\n",
    "        \n",
    "        \n",
    "        return patches\n",
    "img=Image.open('/home/arvind/Documents/352326080611075_0ATT0RLO00011572301890228.png')\n",
    "img=np.asarray(img)\n",
    "print(img.shape)\n",
    "img,_,_=pad_input(img,patch_size=[256,256])\n",
    "print(img.shape)\n",
    "save_path='/home/arvind/Music/patch_save/'\n",
    "fig2 = plt.figure(figsize=(20, 20))\n",
    "p=prediction_patches(img,patch_size=[512,512],stride=256)\n",
    "print(len(p))\n",
    "#for i,j in enumerate(p):\n",
    "    #print(j.shape)\n",
    "    #print(i)\n",
    "    #fig2.add_subplot(8, 4, i+1 )\n",
    "    #plt.imshow(j)\n",
    "    #z=random.randint(1,50)\n",
    "    #cv2.imwrite(save_path+str(i)+'.png',j)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ab20aee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1303, -0.4056, -1.5710,  0.1588,  0.0484,  0.1849, -0.3450,  0.2939,\n",
       "          1.4339, -0.9239],\n",
       "        [-0.5202,  0.6528, -0.8477, -0.9261, -1.8924,  1.2958,  1.3448,  1.5128,\n",
       "         -0.5603,  0.3228],\n",
       "        [-0.3445, -0.5140,  1.4746,  1.0621,  0.4718,  0.8578, -0.9918, -1.0276,\n",
       "         -1.2924,  0.6265],\n",
       "        [ 0.7826, -0.1500, -0.4383, -0.1246, -0.2255,  0.9924,  1.7462, -0.8819,\n",
       "          1.5003, -0.2878]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Linear weight, W,  Y = WX + B\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        # Non-linearity\n",
    "        self.tanh = nn.Tanh()\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity\n",
    "        out = self.tanh(out)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "a=torch.randn([4,28*28])        \n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7aca9027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Parameter containing:\n",
      "tensor([[0.4765, 0.2667, 0.3025, 0.2594]], requires_grad=True)\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "out tensor([[1.8046]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim) \n",
    "        #p=nn.init.normal_(self.fc1.weight,mean=1,std=1)\n",
    "        #print('pzzzzzzzzz',p)\n",
    "        print('weight',self.fc1.weight)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        print(x)\n",
    "        out = self.fc1(x)\n",
    "        print('out',out)\n",
    "        # Non-linearity\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "input_dim = 4\n",
    "hidden_dim = 100\n",
    "output_dim = 1\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "a=torch.ones([1,4])        \n",
    "p=model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "6358efe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.9343e+31, 3.0897e-41, 0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
      "        [0.0000e+00, 2.1019e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[0.6521, 0.5367, 0.9559, 0.8200, 0.5878],\n",
      "        [0.2042, 0.3819, 0.9370, 0.0323, 0.9166],\n",
      "        [0.6074, 0.4282, 0.6365, 0.3749, 0.9475]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9.0192)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "print(w)\n",
    "\n",
    "p=nn.init.uniform_(w)\n",
    "print(p)\n",
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3f255b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.constant_(w, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d6e88cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261ed37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 2560, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def pad_input(input_img,patch_size=[512,512]):\n",
    "        h = input_img.shape[0]\n",
    "        w = input_img.shape[1]\n",
    "        hMod = h % patch_size[0]\n",
    "        wMod = w % patch_size[1]\n",
    "        hPad = 0\n",
    "        wPad = 0\n",
    "        if(hMod!=0 or wMod!=0):\n",
    "            hPad = patch_size[0]-hMod\n",
    "            wPad = patch_size[1]-wMod\n",
    "        output = np.pad(input_img, ((0, hPad),(0,wPad),(0,0)), 'constant')\n",
    "        return output\n",
    "    \n",
    "img=np.zeros([1096,2206,3],dtype='uint8')\n",
    "x=pad_input(img)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "425b356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127, 2213, 3)\n",
      "(1536, 2560, 3)\n",
      "2\n",
      "4\n",
      "8\n",
      "(1024, 1024, 3)\n",
      "0\n",
      "(1024, 1024, 3)\n",
      "1\n",
      "(1024, 1024, 3)\n",
      "2\n",
      "(1024, 1024, 3)\n",
      "3\n",
      "(1024, 1024, 3)\n",
      "4\n",
      "(1024, 1024, 3)\n",
      "5\n",
      "(1024, 1024, 3)\n",
      "6\n",
      "(1024, 1024, 3)\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "fig2 = plt.figure(figsize=(20, 20))\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "def pad_input(input_img,patch_size=[512,512]):\n",
    "        h = input_img.shape[0]\n",
    "        w = input_img.shape[1]\n",
    "        hMod = h % patch_size[0]\n",
    "        wMod = w % patch_size[1]\n",
    "        hPad = 0\n",
    "        wPad = 0\n",
    "        if(hMod!=0 or wMod!=0):\n",
    "            hPad = patch_size[0]-hMod\n",
    "            wPad = patch_size[1]-wMod\n",
    "        output = np.pad(input_img, ((0, hPad),(0,wPad),(0,0)), 'constant')\n",
    "        return(output, hPad,wPad )\n",
    "    \n",
    "def create_patches(img,patch_size=[512,512],stride=256):\n",
    "        #img = np.asarray(img).astype('float32')\n",
    "        #print(img.shape)\n",
    "        assert((img.shape[0]-stride)%stride==0 and (img.shape[1]-stride)%stride==0)\n",
    "        h_patch = int((img.shape[0]-stride)/stride)\n",
    "        w_patch = int((img.shape[1]-stride)/stride)\n",
    "        print(h_patch)\n",
    "        print(w_patch)\n",
    "        patches = []\n",
    "\n",
    "        \n",
    "        \n",
    "        #patch0=img[0:1024,0:1024]\n",
    "        #patch1=img[512:1536,0:1024]\n",
    "        #patchn=img[img.shape[0]-1024:img.shape[0],img.shape[1]-1024:img.shape[1]]\n",
    "        for i in range(h_patch):\n",
    "            y=0\n",
    "            for j in range(w_patch):\n",
    "                if i==0:\n",
    "                    x=0\n",
    "                    patch=img[x:patch_size[0],y:(((j+1)*patch_size[1]))-(j)*stride,:]\n",
    "                    \n",
    "                if i==1:\n",
    "                    x=512\n",
    "                    patch=img[x:patch_size[0]+512,y:(((j+1)*patch_size[1]))-(j)*stride,:]\n",
    "                    \n",
    "                y = ((j+1)*patch_size[1])-(j+1)*stride  \n",
    "                \n",
    "                patches.append(patch)\n",
    "               \n",
    "                    \n",
    "         \n",
    "        \n",
    "        #patches.append(patch0)\n",
    "        #patches.append(patchn)\n",
    "        #patches.append(patch1)\n",
    "        \n",
    "        \n",
    "        return patches\n",
    "img=Image.open('/home/arvind/Documents/352326080611075_0ATT0RLO00011572301890228.png')\n",
    "img=np.asarray(img)\n",
    "print(img.shape)\n",
    "img,_,_=pad_input(img,patch_size=[512,512])\n",
    "print(img.shape)\n",
    "save_path='/home/arvind/Music/patch_save/'\n",
    "fig2 = plt.figure(figsize=(20, 20))\n",
    "p=create_patches(img,patch_size=[1024,1024],stride=512)\n",
    "print(len(p))\n",
    "\n",
    "for i,j in enumerate(p):\n",
    "    print(j.shape)\n",
    "    print(i)\n",
    "    fig2.add_subplot(8, 4, i+1 )\n",
    "    plt.imshow(j)\n",
    "    z=random.randint(1,50)\n",
    "    cv2.imwrite(save_path+str(i)+'.png',j)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc70314",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_original/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/TrainTestVal_5Feb_bg/Labels/**')*1\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/light_train_2x/Labels/**')*2)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_A71/Labels/**')*8)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/train_back_assu/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_crack_camera_cropped/Labels/**')*5)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_FEDEX_aug18/Labels/**')*10)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_lints/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_pink_phones_2x/Labels/**')*5)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_selected_back_cgrade/Labels/**')*2)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_crack_camera/Labels/**')*10)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_light/Labels/**')*3)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_OVERSAMPLE_AUG5/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_SAMSUNG_A51_OVESAMPLE/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/TrainTestVal_5Feb_crack/Labels/**')*10)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/TrainTestVal_5Feb_cups/Labels/**')*5)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_textured/Labels/**')*10)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_textured_Silver/Labels/**')*10)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_back_FEDEX_iphone/Labels/**')*1)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_MUE_APPLE/Labels/**')*2)\n",
    "self.list.extend(glob('/media/HDD8TB3/deepsight_training/2022_deepsight_models_patches/patch_data_creation/patch_creation_codes_annotation_exposure/backpatches_30may2022_512-512/Train/Train_MUE_SAMSUNG/Labels/**')*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05003125",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "\n",
    "       \n",
    "        no = 0\n",
    "        x = 0\n",
    "        for i in range(h_patch):\n",
    "            \n",
    "            y = 0 \n",
    "            for j in range(w_patch):\n",
    "                if i==0 and j==0:\n",
    "   \n",
    "                    patch = img[x:(((i+1)*patch_size[0]))-(i)*stride,y:(((j+1)*patch_size[1]))-(j)*stride,:]\n",
    "                \n",
    "                \n",
    "                #print(patch.shape)\n",
    "                \n",
    "                y = ((j+1)*patch_size[1])-(j+1)*stride\n",
    "                \n",
    "                no+=1\n",
    "                patches.append(patch)\n",
    "            x = ((i+1)*patch_size[0])-(i+1)*stride\n",
    "        \n",
    "        \n",
    "        return patches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
