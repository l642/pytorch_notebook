{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab124fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e932c00",
   "metadata": {},
   "source": [
    "# Tensor basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8ab5d",
   "metadata": {},
   "source": [
    "#### torch.empty() creates tensor with any data type you want, torch.Tensor() only creates tensors of type torch.FloatTensor. So torch.Tensor() is a special case of torch.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb76828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([-1.7806e+27])\n",
      "b: tensor([-1.7806e+27,  4.5698e-41, -2.9059e+07])\n",
      "c: tensor([[-1.7806e+27,  4.5698e-41],\n",
      "        [-2.9109e+07,  3.0733e-41]])\n",
      "d: tensor([[[-1.7806e+27,  4.5698e-41],\n",
      "         [-2.9119e+07,  3.0733e-41],\n",
      "         [ 1.4013e-45,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00]]])\n",
      "tpye of empty tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "##creating empty tensor\n",
    "a=torch.empty(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.empty(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.empty(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.empty(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "print('tpye of empty tensor:', d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd08aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0.7403])\n",
      "b: tensor([0.4947, 0.9709, 0.4873])\n",
      "c: tensor([[0.5341, 0.2587],\n",
      "        [0.4076, 0.8059]])\n",
      "d: tensor([[[0.0275, 0.5968],\n",
      "         [0.7773, 0.7455],\n",
      "         [0.3259, 0.2409]],\n",
      "\n",
      "        [[0.6497, 0.7031],\n",
      "         [0.7782, 0.6036],\n",
      "         [0.4873, 0.3317]]])\n",
      "tpye of rand tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "##creating tensor with random values\n",
    "a=torch.rand(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.rand(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.rand(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.rand(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "print('tpye of rand tensor:', d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e379be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([0.])\n",
      "b: tensor([0., 0., 0.])\n",
      "c: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "d: tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n",
      "e: tensor([1.])\n",
      "f: tensor([1., 1., 1.])\n",
      "g: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "h: tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "## torch with zeros and ones\n",
    "a=torch.zeros(1)   #scaler\n",
    "print('a:',a)\n",
    "b=torch.zeros(3)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.zeros(2,2)  #2-D\n",
    "print('c:',c)\n",
    "d=torch.zeros(2,3,2) #3-D\n",
    "print('d:',d)\n",
    "\n",
    "e=torch.ones(1)   #scaler\n",
    "print('e:',e)\n",
    "f=torch.ones(3)   #1-D\n",
    "print('f:',f)\n",
    "g=torch.ones(2,2)  #2-D\n",
    "print('g:',g)\n",
    "h=torch.ones(2,3,2) #3-D\n",
    "print('h:',h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c742458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e9458ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "c: tensor([[1., 1.],\n",
      "        [1., 1.]], dtype=torch.float16)\n",
      "d: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "##changing data type\n",
    "b=torch.ones(2,2, dtype=torch.int)   #1-D\n",
    "print('b:',b)\n",
    "c=torch.ones(2,2, dtype=torch.float16)   #1-D\n",
    "print('c:',c)\n",
    "d=torch.ones(2,2, dtype=torch.int16)   #1-D\n",
    "print('d:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ba9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "size of b: torch.Size([2, 2])\n",
      "size of b torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "##size of tensor\n",
    "b=torch.ones(2,2, dtype=torch.int)   #1-D\n",
    "print('b:',b)\n",
    "print('size of b:', b.size())\n",
    "print('size of b',b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93bf204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2100, 12.0000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "##another way of creating a tensor\n",
    "\n",
    "a=torch.tensor([1.21,12,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "645558b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0.3676, 0.4455],\n",
      "        [0.4191, 0.4266]])\n",
      "y: tensor([[0.0511, 0.8247],\n",
      "        [0.0444, 0.7447]])\n",
      "a tensor([[0.4187, 1.2702],\n",
      "        [0.4635, 1.1713]])\n",
      "b: tensor([[ 0.3165, -0.3792],\n",
      "        [ 0.3746, -0.3181]])\n",
      "c: tensor([[0.0188, 0.3674],\n",
      "        [0.0186, 0.3177]])\n",
      "d: tensor([[7.1987, 0.5402],\n",
      "        [9.4289, 0.5729]])\n"
     ]
    }
   ],
   "source": [
    "##operation on tensors\n",
    "x=torch.rand(2,2)\n",
    "y=torch.rand(2,2)\n",
    "print('x:',x)\n",
    "print('y:',y)\n",
    "\n",
    "a=x+y\n",
    "a=torch.add(x,y)\n",
    "print('a',a)\n",
    "\n",
    "b=x-y\n",
    "a=torch.sub(x,y)\n",
    "print('b:',b)\n",
    "\n",
    "c=x*y\n",
    "a=torch.mul(x,y)\n",
    "print('c:',c)\n",
    "\n",
    "d=x/y\n",
    "a=torch.div(x,y)\n",
    "print('d:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7571f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8442, 0.5387, 0.9402],\n",
      "        [0.7159, 0.9412, 0.7024],\n",
      "        [0.5917, 0.5546, 0.9049],\n",
      "        [0.5859, 0.2922, 0.0793],\n",
      "        [0.9103, 0.8070, 0.2382]])\n",
      "first row     : tensor([0.8442, 0.5387, 0.9402])\n",
      "first column  : tensor([0.8442, 0.7159, 0.5917, 0.5859, 0.9103])\n",
      "first two row : tensor([[0.8442, 0.5387, 0.9402],\n",
      "        [0.7159, 0.9412, 0.7024]])\n",
      "first two columns : tensor([[0.8442, 0.5387],\n",
      "        [0.7159, 0.9412],\n",
      "        [0.5917, 0.5546],\n",
      "        [0.5859, 0.2922],\n",
      "        [0.9103, 0.8070]])\n",
      "last row: tensor([0.9103, 0.8070, 0.2382])\n",
      "last column: tensor([0.9402, 0.7024, 0.9049, 0.0793, 0.2382])\n",
      "tensor(0.8442)\n",
      "tensor(0.9049)\n",
      "0.8441579341888428\n",
      "0.904884397983551\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(5,3)\n",
    "print(x)\n",
    "print('first row     :',x[0,:])\n",
    "print('first column  :',x[:,0])\n",
    "print('first two row :',x[0:2,:])\n",
    "print('first two columns :',x[:,0:2])\n",
    "print('last row:',x[-1,:])\n",
    "print('last column:',x[:,-1])\n",
    "\n",
    "#printing specific value from tensor\n",
    "a=x[0,0]\n",
    "print(a)\n",
    "b=x[2,2]\n",
    "print(b)\n",
    "\n",
    "#printing actual value from tensor(item only availabe for scaler values)\n",
    "print(x[0,0].item())\n",
    "print(x[2,2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df0d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230],\n",
      "        [0.7598, 0.0444, 0.4070, 0.5096],\n",
      "        [0.3600, 0.0053, 0.2266, 0.7698],\n",
      "        [0.3549, 0.6818, 0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667],\n",
      "        [0.0482, 0.9230],\n",
      "        [0.7598, 0.0444],\n",
      "        [0.4070, 0.5096],\n",
      "        [0.3600, 0.0053],\n",
      "        [0.2266, 0.7698],\n",
      "        [0.3549, 0.6818],\n",
      "        [0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230, 0.7598, 0.0444, 0.4070, 0.5096],\n",
      "        [0.3600, 0.0053, 0.2266, 0.7698, 0.3549, 0.6818, 0.3928, 0.6209]])\n",
      "tensor([[0.0105, 0.3667, 0.0482, 0.9230, 0.7598, 0.0444, 0.4070, 0.5096, 0.3600,\n",
      "         0.0053, 0.2266, 0.7698, 0.3549, 0.6818, 0.3928, 0.6209]])\n"
     ]
    }
   ],
   "source": [
    "##changing dimension of tensor\n",
    "a=torch.rand(4,4)\n",
    "print(a)\n",
    "b=a.view(8,2)\n",
    "print(b)\n",
    "c=a.view(2,-1) ##after giving first dimension it will automatically detect 2 dimension\n",
    "print(c)\n",
    "d=a.view(16,-1) ##after giving first dimension it will automatically detect 2 dimension\n",
    "print(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73d1bf8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 100, 100])\n",
      "torch.Size([4, 256, 10000])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([4,256,100,100])\n",
    "print(x.shape)\n",
    "y=x.view(x.size(0),x.size(1),-1)\n",
    "print(y.shape)\n",
    "z=torch.mean(y,dim=2)\n",
    "print(z.shape)\n",
    "z1=torch.mean(x.view(x.shape[0],x.shape[1],-1),dim=2)\n",
    "print(z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tensor to numpy \n",
    "import numpy as np\n",
    "a=torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print('*'*20)\n",
    "p=a.numpy()\n",
    "print(p)\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2de536fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(2,2)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99ab9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "********************\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "#numpy to tensor\n",
    "a=np.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print('*'*20)\n",
    "b=torch.from_numpy(a)\n",
    "print(b)\n",
    "print(type(b))\n",
    "###NOTE:-the tensor can be converted to numpy only if device is cpu not on gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c4213",
   "metadata": {},
   "source": [
    "# Checking GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e54135fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###cheching whether GPU is avalable or not\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901c98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0.4963, 0.3218, 0.1832, 0.1560, 0.6700])\n",
      "tensor([1.4963, 1.3218, 1.1832, 1.1560, 1.6700])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "else:\n",
    "    device=torch.device(\"cpu\")\n",
    "    x=torch.ones(5,device=device)\n",
    "    print(x)\n",
    "    y=torch.rand(5)\n",
    "    print(y)\n",
    "    y=y.to(device)\n",
    "\n",
    "    z=x+y\n",
    "    \n",
    "    print(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e3102",
   "metadata": {},
   "source": [
    "# Gradient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2424e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9666, 0.2050, 0.3420], requires_grad=True)\n",
      "tensor(12.7650, grad_fn=<MeanBackward0>)\n",
      "tensor([3.9554, 2.9400, 3.1226])\n"
     ]
    }
   ],
   "source": [
    "###Gradient Calculations\n",
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "z=y*y*2\n",
    "z=z.mean()\n",
    "print(z)\n",
    "z.backward() ### means z(scaler) is the error or difference and we have to find grad of z w.r.t x\n",
    "#(When we call .backward() on z, autograd calculates these gradients and stores them in the respective tensorsâ€™ .grad attribute.)\n",
    "print(x.grad)   ######dz/dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51456b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5575, 0.2967, 0.0163], requires_grad=True)\n",
      "tensor([13.0815, 10.5500,  8.1308], grad_fn=<MulBackward0>)\n",
      "tensor([10.2300,  1.8374,  2.4195])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "z=y*y*2\n",
    "#z=z.mean()\n",
    "print(z)\n",
    "u=torch.tensor([1.0,0.2,0.3],dtype=torch.float32)\n",
    "z.backward(u) ### jacobioan (dz/du)\n",
    "print(x.grad)   ######dz/dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c9507",
   "metadata": {},
   "source": [
    "# To stop a tensor tracking the gradient\n",
    "## 1. x.require_grad_(false)\n",
    "## 2. x.detach()\n",
    "## 3. with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a0e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6579, 0.6068, 0.9234], requires_grad=True)\n",
      "tensor([0.6579, 0.6068, 0.9234])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b04b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4569, 0.2485, 0.2689, 0.7756], requires_grad=True)\n",
      "tensor([0.4569, 0.2485, 0.2689, 0.7756])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(4,requires_grad=True)\n",
    "print(y)\n",
    "y=y.detach()\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e907b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3078, 0.1705, 0.4481], requires_grad=True)\n",
      "tensor([2.3078, 2.1705, 2.4481])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y=x+2\n",
    "print(y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfee0cf",
   "metadata": {},
   "source": [
    "# weight.zero.grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "075e8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "# Without zero.grad_()\n",
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    out=(weights*3).sum()\n",
    "    #print(out)\n",
    "    out.backward()\n",
    "    print(weights.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8058f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# With zero.grad_()\n",
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    out=(weights*3).sum()\n",
    "    #print(out)\n",
    "    out.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdecb61",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cbbdca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "###Back propagation\n",
    "x=torch.tensor([1.0])\n",
    "y=torch.tensor([2.0])\n",
    "w=torch.tensor([1.0],requires_grad=True)\n",
    "y_hat=x*w\n",
    "d=y_hat-y\n",
    "loss=d**2\n",
    "##backward propagation\n",
    "loss.backward() ##error\n",
    "print(w.grad) ##dl/dw=(dl/dd)*(dd/dy_hat)*dy_hat/dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab298af",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "016f7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch=1, w = 1.200, loss = 30.00000000\n",
      "epoch=3, w = 1.872, loss = 0.76800019\n",
      "epoch=5, w = 1.980, loss = 0.01966083\n",
      "epoch=7, w = 1.997, loss = 0.00050332\n",
      "epoch=9, w = 1.999, loss = 0.00001288\n",
      "epoch=11, w = 2.000, loss = 0.00000033\n",
      "epoch=13, w = 2.000, loss = 0.00000001\n",
      "epoch=15, w = 2.000, loss = 0.00000000\n",
      "epoch=17, w = 2.000, loss = 0.00000000\n",
      "epoch=19, w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "#####Gradientdescent_manually\n",
    "import numpy as np \n",
    "\n",
    "# Compute every step manually\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# J = MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2x(w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # calculate gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch={epoch+1}, w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2aba16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "###gradientdescent_auto\n",
    "\n",
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor([0.0],requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "def loss(y,y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "lr=0.1\n",
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10== 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedad458",
   "metadata": {},
   "source": [
    "# Training Pipeline: Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7b319413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 3.000, loss = 30.00000000\n",
      "epoch 11: w = 2.001, loss = 0.00002861\n",
      "epoch 21: w = 2.000, loss = 0.00000000\n",
      "epoch 31: w = 2.000, loss = 0.00000000\n",
      "epoch 41: w = 2.000, loss = 0.00000000\n",
      "epoch 51: w = 2.000, loss = 0.00000000\n",
      "epoch 61: w = 2.000, loss = 0.00000000\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "###Training Pipeline: Model, Loss, and Optimizer\n",
    "import torch.nn as nn\n",
    "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "w=torch.tensor([0.0],requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "lr=0.1\n",
    "loss=nn.MSELoss()    ###using loss as predefined\n",
    "optimizer=torch.optim.SGD([w],lr=lr)   ##optimizer\n",
    "\n",
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    y_pred=forward(x)\n",
    "    l=loss(y,y_pred)\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10== 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9a825c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "epochs:1, loss:54.546833\n",
      "epochs:11, loss:0.065913\n",
      "epochs:21, loss:0.026023\n",
      "epochs:31, loss:0.014166\n",
      "epochs:41, loss:0.007713\n",
      "epochs:51, loss:0.004200\n",
      "epochs:61, loss:0.002287\n",
      "epochs:71, loss:0.001245\n",
      "epochs:81, loss:0.000678\n",
      "epochs:91, loss:0.000369\n",
      "Prediction after training = 9.976\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "#print(x.shape)\n",
    "n_samples,n_features=x.shape[0],x.shape[1]\n",
    "print(n_samples,n_features)\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "model=nn.Linear(input_size,output_size)\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "n_epochs=100\n",
    "for epoch in range(n_epochs):\n",
    "    output=model(x)\n",
    "    #print(output)\n",
    "    #print(output.shape)\n",
    "    l=loss(y,output)\n",
    "    #print(l.item())\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"epochs:{epoch+1}, loss:{l.item():3f}\")\n",
    "print(f'Prediction after training = {model(x_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f328128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "epochs:1, loss:20.859375\n",
      "epochs:11, loss:0.157385\n",
      "epochs:21, loss:0.081965\n",
      "epochs:31, loss:0.044627\n",
      "epochs:41, loss:0.024298\n",
      "epochs:51, loss:0.013230\n",
      "epochs:61, loss:0.007203\n",
      "epochs:71, loss:0.003922\n",
      "epochs:81, loss:0.002135\n",
      "epochs:91, loss:0.001163\n",
      "Prediction after training = 9.957\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
    "x_test=torch.tensor([5],dtype=torch.float32)\n",
    "#print(x.shape)\n",
    "n_samples,n_features=x.shape[0],x.shape[1]\n",
    "print(n_samples,n_features)\n",
    "input_size=n_features\n",
    "output_size=n_features\n",
    "\n",
    "class LinearReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearReg,self).__init__()\n",
    "        \n",
    "        self.Lin=nn.Linear(input_size,output_size)\n",
    "    def forward(self,x):\n",
    "        x=self.Lin(x)\n",
    "        return x\n",
    "model=LinearReg()   \n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "n_epochs=100\n",
    "for epoch in range(n_epochs):\n",
    "    output=model(x)\n",
    "    #print(output)\n",
    "    #print(output.shape)\n",
    "    l=loss(y,output)\n",
    "    #print(l.item())\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f\"epochs:{epoch+1}, loss:{l.item():3f}\")\n",
    "print(f'Prediction after training = {model(x_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ed5e8",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a597e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normal Folder wise\n",
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,path='/home/arvind/Videos/classification/test',augmentation=True,dim=(100,100)):\n",
    "        self.dim=dim\n",
    "        self.img_list=glob.glob('/home/arvind/Videos/classification/test/**/**')\n",
    "        #self.label=[i.split('/')[-2] for i in self.img_list]\n",
    "        self.dict={\"building\":0,\"forest\":1}\n",
    "        self.augmentation=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.2),\n",
    "        #GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.2)\n",
    "        ],p=0.6)\n",
    "    def augment(self,img):\n",
    "        aug_img=self.augmentation(image=img)\n",
    "        return aug_img['image'] \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.img_list[index]\n",
    "        labels=img.split('/')[-2]\n",
    "        img=Image.open(img)\n",
    "        img = img.resize(self.dim)\n",
    "        img=np.asarray(img)/255\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img=self.augment(img)\n",
    "        labels=self.dict[labels]\n",
    "        return torch.FloatTensor(img.transpose(2,0,1)),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "train=DataLoader(Train(path='/home/arvind/Videos/intel/train/**/**'),batch_size=4)\n",
    "for image, label in train:\n",
    "    print(image.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2e3730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSV \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from albumentations import *\n",
    "class Train(Dataset):\n",
    "    def __init__(self,csv_path=\"/home/arvind/Videos/classification/testing.csv\",augment=True,dim=(500,500),batch_size=4):\n",
    "        self.batch_size=batch_size\n",
    "        self.dim=dim\n",
    "        self.df=pd.read_csv('/home/arvind/Videos/classification/testing.csv')\n",
    "        self.image=self.df['path'].tolist()\n",
    "        self.label=self.df['label'].tolist()\n",
    "        self.dict={'forest':0,'building':1}\n",
    "        self.aug=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),],p=0.6)\n",
    "    \n",
    "    def augmentation(self,img):\n",
    "        img=self.aug(image=img)\n",
    "        return aug['image']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.image[index]\n",
    "        label=self.label[index]\n",
    "        labels=self.dict[label]\n",
    "        img=Image.open(img)\n",
    "        img=img.resize(self.dim)\n",
    "        img=np.asarray(img)\n",
    "        if selg.augment:\n",
    "            img=self.augmentation(img)\n",
    "            \n",
    "        return torch.FloatTensor(img.transpose(2,0,1)),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "        \n",
    "        \n",
    "        \n",
    "train=DataLoader(Train(csv_path=\"/home/arvind/Videos/classification/testing.csv\",augment=True,dim=(100,100),batch_size=4))\n",
    "for image,label in train:\n",
    "    print(image.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "970f8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-106293712ba3>:58: FutureWarning: rgb2grey is deprecated. It will be removed in version 0.19.Please use rgb2gray instead.\n",
      "  label=rgb2grey(np.asarray(label))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 1024, 1024])\n",
      "torch.Size([4, 3, 572, 572])\n"
     ]
    }
   ],
   "source": [
    "# Segmentation DataLoader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,img_path='/home/arvind/Videos/segmentation/Data/train',augmentation=True):\n",
    "        self.augmentation=augmentation\n",
    "        self.img=glob.glob('/home/arvind/Videos/segmentation/Data/train/image/**')\n",
    "        self.label=glob.glob('/home/arvind/Videos/segmentation/Data/train/mask/**')\n",
    "        self.aug = Compose([Rotate(limit = (5.,10.),p=0.5),OneOf([HorizontalFlip(p=0.5),VerticalFlip(p=0.5)]),\n",
    "        RandomBrightnessContrast(p=0.5,brightness_limit=0.2,contrast_limit=0.2),HueSaturationValue(p=0.3)],p=0.5,additional_targets={'mask_full':'mask'})\n",
    "\n",
    "    def augment(self,image,mask):\n",
    "        aug_img=self.aug(image=image,mask=mask)\n",
    "        return aug_img['image'],aug_img['mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __to_categorical__(self,mask):\n",
    "        \n",
    "        #Function to convert labels into categorical\n",
    "        mask_bg = np.zeros((mask.shape[0],mask.shape[1]))\n",
    "        mask_car = np.zeros((mask.shape[0],mask.shape[1]))\n",
    "         \n",
    "        mask_car[mask==1] = 1\n",
    "        mask_bg[mask==0] = 1\n",
    "        mask =np.concatenate((mask_bg[np.newaxis],mask_car[np.newaxis]),axis = 0)\n",
    "        return mask.astype(np.float32)\n",
    "    \n",
    "    def make_class_label(self,label):\n",
    "        \n",
    "        label[label==1] = 255\n",
    "        label[label==0] = 0\n",
    "        return np.uint8(label)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        images=self.img[index]\n",
    "        #label=images.replace('/image/','/mask/')\n",
    "        label=self.label[index]\n",
    "        image=Image.open(images).convert('RGB')\n",
    "        image=image.resize((572,572))\n",
    "        image=np.asarray(image)\n",
    "       \n",
    "\n",
    "        \n",
    "        label=Image.open(label).convert(\"RGB\")\n",
    "        label=label.resize((1024,1024))\n",
    "        label=rgb2grey(np.asarray(label))\n",
    "        label=self.make_class_label(label)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            image,label= self.augment(image,label)\n",
    "        label = self.__to_categorical__(label)\n",
    "        return torch.FloatTensor(image).permute(2,1,0),torch.FloatTensor(label)\n",
    "        \n",
    "train_loader= DataLoader(Train(), batch_size=4)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for (imag1, labels) in train_loader:\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(labels.shape)\n",
    "    print(imag1.shape)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89328bf5",
   "metadata": {},
   "source": [
    "# Transforms in Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "44f5dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms as t\n",
    "from torchvision.transforms import Compose\n",
    "from albumentations import *\n",
    "\n",
    "class Train(Dataset):\n",
    "    def __init__(self,path='/home/arvind/Videos/classification/test',augmentation=True,dim=(100,100),transform=None):\n",
    "        self.dim=dim\n",
    "        self.img_list=glob.glob('/home/arvind/Videos/classification/test/**/**')\n",
    "        #self.label=[i.split('/')[-2] for i in self.img_list]\n",
    "        self.dict={\"building\":0,\"forest\":1}\n",
    "        self.augmentation=Compose([Rotate(limit = (1.,10.),p=0.5),Flip(0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.2),\n",
    "        #CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.2),\n",
    "        #GaussNoise(var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.2)\n",
    "        ],p=0.6)\n",
    "        self.transform=transform\n",
    "    def augment(self,img):\n",
    "        aug_img=self.augmentation(image=img)\n",
    "        return aug_img['image'] \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img=self.img_list[index]\n",
    "        labels=img.split('/')[-2]\n",
    "        img=Image.open(img)\n",
    "        img = img.resize(self.dim)\n",
    "        img=np.asarray(img)/255\n",
    "        \n",
    "        if self.augmentation:\n",
    "            img=self.augment(img)\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "            \n",
    "        labels=self.dict[labels]\n",
    "        return torch.FloatTensor(img),torch.LongTensor([labels])\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "train_transform = t.Compose([t.ToTensor(),\n",
    "                                t.Normalize((0.5, 0.5, 0.5), \n",
    "                                                     (0.5, 0.5, 0.5))])\n",
    "train=DataLoader(Train(path='/home/arvind/Videos/classification/test/**',transform=train_transform),batch_size=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f7ded",
   "metadata": {},
   "source": [
    "# Softmax and Cross-Entopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43bbe91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4223188 0.1553624 0.4223188]\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 2])\n",
    "outputs = softmax(x)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a9fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1:0.357\n",
      "loss2:0.511\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual*np.log(predicted))\n",
    "x=np.asarray([1,0,0,0])\n",
    "y=np.asarray([0.7,0.1,0.1,0.1])\n",
    "z=np.asarray([0.6,0.2,0.1,0.1]) ## loss will increase\n",
    "loss1=cross_entropy(x,y)\n",
    "loss2=cross_entropy(x,z)\n",
    "\n",
    "print(f\"loss1:{loss1:0.3f}\")\n",
    "print(f\"loss2:{loss2:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad77f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of y:  tensor([0])\n",
      "pred 1:  tensor([0])\n",
      "pred 2:  tensor([1])\n",
      "PyTorch Loss1: 0.4170\n",
      "PyTorch Loss2: 1.8406\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "y1=torch.tensor([1])\n",
    "print('value of y: ',Y)\n",
    "\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "_,pred1=torch.max(Y_pred_good,1)\n",
    "print('pred 1: ',pred1)\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "_,pred2=torch.max(Y_pred_bad,1)\n",
    "print('pred 2: ',pred2)\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7abeb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1:0.417\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual*np.log(predicted))\n",
    "x=np.asarray([1,0,0])\n",
    "y=np.asarray([2.0, 1.0, 0.1])\n",
    "y=softmax(y)\n",
    "loss1=cross_entropy(x,y)\n",
    "\n",
    "print(f\"loss1:{loss1:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb32f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred1 torch.return_types.max(\n",
      "values=tensor([3.9000, 1.2000, 2.3000, 2.2000]),\n",
      "indices=tensor([2, 0, 3, 1]))\n",
      "pred2 torch.return_types.max(\n",
      "values=tensor([5.0000, 2.0000, 1.5000, 2.2000]),\n",
      "indices=tensor([3, 3, 3, 1]))\n",
      "Batch Loss1:  1.1150\n",
      "Batch Loss2: 3.0347\n"
     ]
    }
   ],
   "source": [
    "### Loss for batch size of 4\n",
    "Y = torch.tensor([2,0,1,0])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9,0.6], # predict class 2\n",
    "    [1.2, 0.1, 0.3,0.9], # predict class 0\n",
    "    [0.3, 2.2, 0.2,2.3],\n",
    "     [0.3, 2.2, 0.1,1.9]]) # predict class 1\n",
    "pred1=torch.max(Y_pred_good,1)\n",
    "print('pred1',pred1)\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1,5.0],\n",
    "    [0.1, 0.3, 1.5,2.0],\n",
    "    [1.2, 0.2, 0.5,1.5],\n",
    "    [0.3, 2.2, 0.2,1.5]])\n",
    "pred2=torch.max(Y_pred_bad,1)\n",
    "print('pred2',pred2)\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45684c2",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "609d8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fc3 torch.Size([4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0003,  0.1476,  0.0313, -0.1012],\n",
       "        [-0.0003,  0.1484,  0.0312, -0.1008],\n",
       "        [ 0.0002,  0.1477,  0.0313, -0.1010],\n",
       "        [ 0.0010,  0.1478,  0.0307, -0.1012]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,n_class=4,n_channels=3):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=24,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=24,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=32,out_features=256)\n",
    "        self.fc2=nn.Linear(in_features=256,out_features=128)\n",
    "        self.fc3=nn.Linear(in_features=128,out_features=4)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool2(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x=self.pool3(x)\n",
    "        #print('before flatting: ',x.shape)\n",
    "        x=x.view(x.size(0),x.size(1),-1)\n",
    "        #print('on doing flatting: ',x.shape)\n",
    "        x=torch.mean(x,dim=2)\n",
    "        #print('after calculating mean: ',x.shape)\n",
    "        #print('flatting',x.shape)\n",
    "        \n",
    "        x=self.fc1(x)\n",
    "        #print('after fc1',x.shape)\n",
    "        x=self.fc2(x)\n",
    "        #print('after fc2',x.shape)\n",
    "        x=self.fc3(x)\n",
    "        print('after fc3',x.shape)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model=CNN(n_class=4)\n",
    "x=torch.randn(4,3,256,256)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvind/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "###segmentation model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "x=torch.randn(4,3,1024,1024)\n",
    "model=UNet(n_class=4)\n",
    "model(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b95a7",
   "metadata": {},
   "source": [
    "## Adaptive Avarage Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b203e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "m = nn.AdaptiveAvgPool2d((5,7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056b35a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2009)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_cross_entropy(y_, y): \n",
    "    return -(y_.log()*y + (1-y)*(1-y_).log()).mean()\n",
    "\n",
    "y=torch.rand([1,1,12,8])\n",
    "y_=torch.rand([1,1,12,8])\n",
    "loss = binary_cross_entropy(y_, y)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c43b9",
   "metadata": {},
   "source": [
    "# Attention Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d78a46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 100, 100])\n",
      "torch.Size([4, 1, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1382,  0.0885,  0.2156,  ...,  0.2409,  0.1734,  0.1402],\n",
       "          [ 0.1611,  0.1879,  0.0779,  ...,  0.1017,  0.1426,  0.1705],\n",
       "          [ 0.2138,  0.1151,  0.2065,  ...,  0.0866,  0.0567,  0.2231],\n",
       "          ...,\n",
       "          [ 0.1446,  0.1508,  0.1730,  ...,  0.2398, -0.0120,  0.1381],\n",
       "          [ 0.0363,  0.1807,  0.1683,  ..., -0.0241,  0.0316,  0.2043],\n",
       "          [ 0.2821,  0.1444,  0.1310,  ...,  0.0134,  0.1966,  0.1532]]],\n",
       "\n",
       "\n",
       "        [[[-0.0187,  0.0305,  0.1288,  ...,  0.2258,  0.1170,  0.2328],\n",
       "          [ 0.0684,  0.1204,  0.1484,  ...,  0.1411,  0.1879,  0.2117],\n",
       "          [ 0.2195,  0.1852,  0.0763,  ...,  0.1434,  0.1718, -0.0779],\n",
       "          ...,\n",
       "          [ 0.0514,  0.0251,  0.2610,  ...,  0.1701,  0.1108,  0.1688],\n",
       "          [ 0.0590,  0.1551,  0.1032,  ...,  0.1173,  0.1498,  0.1180],\n",
       "          [ 0.1084,  0.1637,  0.1118,  ...,  0.1246,  0.1552,  0.2572]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2159,  0.2421,  0.0720,  ...,  0.0543,  0.1283, -0.0170],\n",
       "          [ 0.2517,  0.3363,  0.1979,  ...,  0.0046,  0.0250,  0.0489],\n",
       "          [ 0.1958,  0.3489,  0.1650,  ...,  0.1571,  0.1801,  0.0780],\n",
       "          ...,\n",
       "          [ 0.1080,  0.1711, -0.0196,  ...,  0.1268,  0.2127,  0.1989],\n",
       "          [ 0.0969,  0.0765,  0.0529,  ...,  0.2126,  0.2426, -0.0235],\n",
       "          [ 0.0474,  0.2143,  0.2465,  ...,  0.1366,  0.0864,  0.1458]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1457,  0.0565,  0.0867,  ...,  0.1757,  0.0802,  0.2964],\n",
       "          [ 0.1078,  0.0853,  0.1192,  ...,  0.1099,  0.1258,  0.2254],\n",
       "          [ 0.0687,  0.1433,  0.2445,  ...,  0.2039,  0.1471, -0.0457],\n",
       "          ...,\n",
       "          [ 0.1568,  0.2102,  0.1381,  ..., -0.0057,  0.0564,  0.1839],\n",
       "          [ 0.0664,  0.1167,  0.0790,  ...,  0.1091,  0.0595,  0.1639],\n",
       "          [ 0.0726,  0.1197,  0.1878,  ...,  0.0187, -0.0213,  0.1769]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spatial Attention\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.conv2 (x)\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9ce75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([4, 32, 100, 100])\n",
      "torch.Size([4, 1, 100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0262, 0.0522, 0.8230,  ..., 0.4913, 0.2711, 0.6350],\n",
       "          [0.3761, 0.1114, 0.9824,  ..., 0.4967, 0.9155, 0.7620],\n",
       "          [0.3279, 0.3883, 0.3882,  ..., 0.7728, 0.0851, 0.4713],\n",
       "          ...,\n",
       "          [0.0270, 0.4382, 0.4280,  ..., 0.9941, 0.5767, 0.0607],\n",
       "          [0.3417, 0.7304, 0.5603,  ..., 0.9621, 0.6954, 0.3495],\n",
       "          [0.4599, 0.8446, 0.0960,  ..., 0.0275, 0.3741, 0.0995]],\n",
       "\n",
       "         [[0.2884, 0.0569, 0.4078,  ..., 0.5882, 0.5662, 0.1987],\n",
       "          [0.6087, 0.6621, 0.0903,  ..., 0.7807, 0.8314, 0.7223],\n",
       "          [0.2364, 0.4533, 0.2001,  ..., 0.5693, 0.0633, 0.6276],\n",
       "          ...,\n",
       "          [0.9429, 0.6904, 0.8040,  ..., 0.7896, 0.4480, 0.2987],\n",
       "          [0.9212, 0.9352, 0.7983,  ..., 0.1570, 0.0684, 0.0560],\n",
       "          [0.9440, 0.2931, 0.1291,  ..., 0.1171, 0.1115, 0.6850]],\n",
       "\n",
       "         [[0.4524, 0.6719, 0.1480,  ..., 0.5947, 0.7498, 0.6563],\n",
       "          [0.8591, 0.5761, 0.7877,  ..., 0.6060, 0.0568, 0.7443],\n",
       "          [0.7241, 0.9386, 0.6230,  ..., 0.7046, 0.1483, 0.4096],\n",
       "          ...,\n",
       "          [0.9658, 0.5137, 0.5318,  ..., 0.2719, 0.3960, 0.2348],\n",
       "          [0.4983, 0.8760, 0.3591,  ..., 0.0307, 0.3869, 0.5271],\n",
       "          [0.8526, 0.6226, 0.2823,  ..., 0.5965, 0.8526, 0.0996]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.4442, 0.8174, 0.1411,  ..., 0.2477, 0.5125, 0.1158],\n",
       "          [0.3495, 0.0446, 0.2935,  ..., 0.4099, 0.0902, 0.7506],\n",
       "          [0.9263, 0.2637, 0.5487,  ..., 0.5670, 0.1511, 0.9889],\n",
       "          ...,\n",
       "          [0.8132, 0.1021, 0.7814,  ..., 0.4469, 0.2391, 0.1581],\n",
       "          [0.1272, 0.9510, 0.9410,  ..., 0.7289, 0.1008, 0.2225],\n",
       "          [0.4291, 0.9807, 0.9541,  ..., 0.5516, 0.8229, 0.3356]],\n",
       "\n",
       "         [[0.6979, 0.5389, 0.2628,  ..., 0.2546, 0.4466, 0.4271],\n",
       "          [0.4489, 0.5730, 0.4470,  ..., 0.7385, 0.7680, 0.2157],\n",
       "          [0.5605, 0.9801, 0.3192,  ..., 0.4556, 0.6931, 0.2688],\n",
       "          ...,\n",
       "          [0.7439, 0.8595, 0.8755,  ..., 0.4963, 0.2006, 0.0082],\n",
       "          [0.6366, 0.8386, 0.9381,  ..., 0.9706, 0.1446, 0.8994],\n",
       "          [0.6228, 0.3193, 0.4212,  ..., 0.4670, 0.1133, 0.6483]],\n",
       "\n",
       "         [[0.5409, 0.0711, 0.7738,  ..., 0.2934, 0.2047, 0.3555],\n",
       "          [0.5217, 0.5292, 0.0655,  ..., 0.3859, 0.9571, 0.3693],\n",
       "          [0.6749, 0.1287, 0.3810,  ..., 0.0536, 0.0726, 0.0895],\n",
       "          ...,\n",
       "          [0.7730, 0.2480, 0.0304,  ..., 0.3164, 0.2971, 0.4836],\n",
       "          [0.2668, 0.3119, 0.0792,  ..., 0.7670, 0.9483, 0.9536],\n",
       "          [0.4905, 0.4159, 0.9802,  ..., 0.4296, 0.2362, 0.1636]]],\n",
       "\n",
       "\n",
       "        [[[0.2885, 0.3425, 0.6757,  ..., 0.0669, 0.0820, 0.2498],\n",
       "          [0.1979, 0.8434, 0.4572,  ..., 0.7189, 0.5274, 0.7179],\n",
       "          [0.5346, 0.8013, 0.5023,  ..., 0.8045, 0.5344, 0.3468],\n",
       "          ...,\n",
       "          [0.1968, 0.8654, 0.0343,  ..., 0.0534, 0.6034, 0.1162],\n",
       "          [0.4183, 0.3966, 0.2879,  ..., 0.4365, 0.3918, 0.6882],\n",
       "          [0.9416, 0.4108, 0.7740,  ..., 0.8878, 0.8935, 0.6738]],\n",
       "\n",
       "         [[0.7054, 0.9801, 0.1005,  ..., 0.3132, 0.4650, 0.7571],\n",
       "          [0.1879, 0.0566, 0.8501,  ..., 0.1440, 0.6961, 0.6305],\n",
       "          [0.8978, 0.4098, 0.0431,  ..., 0.5740, 0.7672, 0.4359],\n",
       "          ...,\n",
       "          [0.9522, 0.7564, 0.5072,  ..., 0.6540, 0.0662, 0.4715],\n",
       "          [0.0633, 0.2684, 0.9325,  ..., 0.3585, 0.3928, 0.8213],\n",
       "          [0.4235, 0.3412, 0.1298,  ..., 0.5248, 0.8626, 0.7266]],\n",
       "\n",
       "         [[0.6662, 0.8095, 0.8099,  ..., 0.5881, 0.8330, 0.6694],\n",
       "          [0.3126, 0.2352, 0.4927,  ..., 0.5732, 0.6028, 0.3269],\n",
       "          [0.3489, 0.0142, 0.4282,  ..., 0.8920, 0.4481, 0.4988],\n",
       "          ...,\n",
       "          [0.4020, 0.6658, 0.1228,  ..., 0.8206, 0.6205, 0.5989],\n",
       "          [0.2825, 0.8635, 0.2508,  ..., 0.0123, 0.0519, 0.2882],\n",
       "          [0.6276, 0.2149, 0.2640,  ..., 0.7075, 0.5036, 0.3051]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7110, 0.6314, 0.8233,  ..., 0.9678, 0.5147, 0.9763],\n",
       "          [0.7020, 0.8506, 0.8204,  ..., 0.9128, 0.6878, 0.7093],\n",
       "          [0.5359, 0.2152, 0.1375,  ..., 0.4984, 0.2278, 0.2476],\n",
       "          ...,\n",
       "          [0.8050, 0.1958, 0.3391,  ..., 0.6265, 0.3175, 0.9449],\n",
       "          [0.0349, 0.3724, 0.4460,  ..., 0.0605, 0.8523, 0.9166],\n",
       "          [0.5271, 0.6821, 0.7525,  ..., 0.7660, 0.0487, 0.5736]],\n",
       "\n",
       "         [[0.9890, 0.9703, 0.0739,  ..., 0.0328, 0.3047, 0.0462],\n",
       "          [0.6180, 0.7275, 0.5821,  ..., 0.8851, 0.6304, 0.7262],\n",
       "          [0.3896, 0.1482, 0.7246,  ..., 0.1500, 0.1815, 0.2098],\n",
       "          ...,\n",
       "          [0.4394, 0.2678, 0.9309,  ..., 0.6334, 0.2624, 0.3467],\n",
       "          [0.5623, 0.9433, 0.4849,  ..., 0.3660, 0.6656, 0.0234],\n",
       "          [0.4994, 0.1446, 0.6525,  ..., 0.8292, 0.0410, 0.6219]],\n",
       "\n",
       "         [[0.7735, 0.4664, 0.5501,  ..., 0.5804, 0.8851, 0.3601],\n",
       "          [0.1945, 0.9392, 0.2154,  ..., 0.3362, 0.7419, 0.5826],\n",
       "          [0.4889, 0.4635, 0.4307,  ..., 0.9684, 0.9467, 0.4837],\n",
       "          ...,\n",
       "          [0.7853, 0.4879, 0.4199,  ..., 0.0627, 0.4502, 0.2485],\n",
       "          [0.0077, 0.1522, 0.8240,  ..., 0.5665, 0.6403, 0.5560],\n",
       "          [0.4752, 0.1050, 0.8243,  ..., 0.8687, 0.2064, 0.4654]]],\n",
       "\n",
       "\n",
       "        [[[0.0583, 0.3563, 0.9657,  ..., 0.2308, 0.4147, 0.2167],\n",
       "          [0.1151, 0.5513, 0.0272,  ..., 0.0350, 0.3347, 0.9817],\n",
       "          [0.4777, 0.6856, 0.8178,  ..., 0.6942, 0.4436, 0.9892],\n",
       "          ...,\n",
       "          [0.1532, 0.5849, 0.8901,  ..., 0.4721, 0.4507, 0.6657],\n",
       "          [0.2089, 0.7186, 0.7575,  ..., 0.6702, 0.7512, 0.5019],\n",
       "          [0.3218, 0.9978, 0.5455,  ..., 0.8909, 0.3220, 0.2205]],\n",
       "\n",
       "         [[0.3418, 0.2225, 0.4379,  ..., 0.8198, 0.5278, 0.4433],\n",
       "          [0.5416, 0.4667, 0.9198,  ..., 0.2573, 0.5669, 0.2935],\n",
       "          [0.5211, 0.5550, 0.6941,  ..., 0.2272, 0.7032, 0.6999],\n",
       "          ...,\n",
       "          [0.9214, 0.6686, 0.3826,  ..., 0.3004, 0.2619, 0.1479],\n",
       "          [0.1738, 0.7411, 0.4187,  ..., 0.8050, 0.5598, 0.7524],\n",
       "          [0.0229, 0.0328, 0.0200,  ..., 0.4405, 0.5618, 0.5362]],\n",
       "\n",
       "         [[0.5395, 0.1157, 0.7537,  ..., 0.4276, 0.2534, 0.4950],\n",
       "          [0.8670, 0.6990, 0.8506,  ..., 0.8472, 0.9464, 0.3653],\n",
       "          [0.8168, 0.3216, 0.7558,  ..., 0.8679, 0.9149, 0.6833],\n",
       "          ...,\n",
       "          [0.2528, 0.5655, 0.1347,  ..., 0.8742, 0.1020, 0.4900],\n",
       "          [0.3330, 0.3629, 0.0682,  ..., 0.7720, 0.8644, 0.4743],\n",
       "          [0.8249, 0.6235, 0.4332,  ..., 0.8842, 0.6561, 0.1324]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0777, 0.2430, 0.7162,  ..., 0.3059, 0.2886, 0.3431],\n",
       "          [0.9973, 0.9552, 0.5114,  ..., 0.3230, 0.4878, 0.6658],\n",
       "          [0.5594, 0.5402, 0.8867,  ..., 0.7300, 0.6848, 0.7936],\n",
       "          ...,\n",
       "          [0.1079, 0.5500, 0.2845,  ..., 0.0408, 0.3075, 0.9315],\n",
       "          [0.8099, 0.4189, 0.7981,  ..., 0.4635, 0.9811, 0.6486],\n",
       "          [0.8430, 0.5382, 0.5867,  ..., 0.3066, 0.6073, 0.4955]],\n",
       "\n",
       "         [[0.5605, 0.7006, 0.2266,  ..., 0.4414, 0.1854, 0.6927],\n",
       "          [0.9294, 0.5456, 0.4772,  ..., 0.4604, 0.5251, 0.7234],\n",
       "          [0.6079, 0.5184, 0.3423,  ..., 0.1076, 0.3973, 0.2888],\n",
       "          ...,\n",
       "          [0.1073, 0.4080, 0.7038,  ..., 0.3834, 0.2628, 0.0148],\n",
       "          [0.6904, 0.6381, 0.0141,  ..., 0.6653, 0.2549, 0.1996],\n",
       "          [0.4923, 0.3276, 0.2483,  ..., 0.6991, 0.1931, 0.1580]],\n",
       "\n",
       "         [[0.5081, 0.0324, 0.4406,  ..., 0.4677, 0.6714, 0.1821],\n",
       "          [0.1294, 0.4977, 0.4169,  ..., 0.7417, 0.5615, 0.2202],\n",
       "          [0.8959, 0.3745, 0.4188,  ..., 0.8153, 0.0722, 0.2335],\n",
       "          ...,\n",
       "          [0.7663, 0.5742, 0.0750,  ..., 0.2651, 0.2103, 0.7338],\n",
       "          [0.2519, 0.7637, 0.2665,  ..., 0.2211, 0.3723, 0.3497],\n",
       "          [0.0475, 0.3189, 0.4702,  ..., 0.0027, 0.9319, 0.7713]]],\n",
       "\n",
       "\n",
       "        [[[0.1749, 0.5558, 0.1727,  ..., 0.0721, 0.2416, 0.2575],\n",
       "          [0.7624, 0.7715, 0.1136,  ..., 0.3706, 0.5635, 0.3337],\n",
       "          [0.2396, 0.5079, 0.6395,  ..., 0.5119, 0.2188, 0.5952],\n",
       "          ...,\n",
       "          [0.3289, 0.4981, 0.2714,  ..., 0.2928, 0.6711, 0.9904],\n",
       "          [0.6742, 0.8923, 0.6009,  ..., 0.5225, 0.7293, 0.6001],\n",
       "          [0.7086, 0.4494, 0.5108,  ..., 0.9458, 0.8544, 0.9722]],\n",
       "\n",
       "         [[0.9190, 0.4387, 0.1412,  ..., 0.4370, 0.6768, 0.8117],\n",
       "          [0.0382, 0.3294, 0.9318,  ..., 0.2376, 0.7589, 0.1583],\n",
       "          [0.5118, 0.8589, 0.6123,  ..., 0.5586, 0.2752, 0.3312],\n",
       "          ...,\n",
       "          [0.2123, 0.7204, 0.4555,  ..., 0.1485, 0.5209, 0.0835],\n",
       "          [0.9133, 0.2106, 0.9254,  ..., 0.4712, 0.8266, 0.9825],\n",
       "          [0.2824, 0.2932, 0.1155,  ..., 0.1794, 0.6665, 0.9061]],\n",
       "\n",
       "         [[0.5355, 0.7170, 0.4123,  ..., 0.0851, 0.1867, 0.4219],\n",
       "          [0.2790, 0.9407, 0.3397,  ..., 0.3525, 0.4975, 0.8882],\n",
       "          [0.4233, 0.1082, 0.1746,  ..., 0.6068, 0.8439, 0.7832],\n",
       "          ...,\n",
       "          [0.2521, 0.1286, 0.6149,  ..., 0.7161, 0.9565, 0.6477],\n",
       "          [0.1824, 0.3761, 0.1802,  ..., 0.0699, 0.5893, 0.6499],\n",
       "          [0.2593, 0.6647, 0.2085,  ..., 0.2334, 0.0997, 0.6775]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.7010, 0.1417, 0.0253,  ..., 0.2241, 0.3846, 0.1204],\n",
       "          [0.0914, 0.0357, 0.3339,  ..., 0.0738, 0.3975, 0.2792],\n",
       "          [0.6229, 0.1219, 0.3080,  ..., 0.8033, 0.9016, 0.4112],\n",
       "          ...,\n",
       "          [0.7245, 0.6326, 0.5173,  ..., 0.2624, 0.1842, 0.8319],\n",
       "          [0.0663, 0.9437, 0.5578,  ..., 0.8310, 0.0172, 0.0611],\n",
       "          [0.4053, 0.1694, 0.4447,  ..., 0.5649, 0.8711, 0.5145]],\n",
       "\n",
       "         [[0.9946, 0.0688, 0.9932,  ..., 0.1411, 0.4004, 0.8011],\n",
       "          [0.2958, 0.9664, 0.1100,  ..., 0.9220, 0.5016, 0.5699],\n",
       "          [0.4086, 0.1178, 0.6765,  ..., 0.4409, 0.1215, 0.6514],\n",
       "          ...,\n",
       "          [0.2299, 0.5011, 0.1878,  ..., 0.9479, 0.7163, 0.0343],\n",
       "          [0.6468, 0.2648, 0.4067,  ..., 0.6964, 0.0436, 0.5022],\n",
       "          [0.0406, 0.6285, 0.7618,  ..., 0.8760, 0.8370, 0.1056]],\n",
       "\n",
       "         [[0.5872, 0.0827, 0.1658,  ..., 0.8340, 0.6513, 0.9256],\n",
       "          [0.0405, 0.9015, 0.9090,  ..., 0.7219, 0.7133, 0.8177],\n",
       "          [0.8758, 0.3901, 0.2161,  ..., 0.3943, 0.2226, 0.2665],\n",
       "          ...,\n",
       "          [0.2289, 0.6573, 0.5814,  ..., 0.7686, 0.7822, 0.4272],\n",
       "          [0.2172, 0.7049, 0.8779,  ..., 0.3226, 0.3890, 0.7185],\n",
       "          [0.7196, 0.5786, 0.8922,  ..., 0.8927, 0.5692, 0.3235]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        print(self.in_ch)\n",
    "        self.attn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation),\n",
    "            nn.BatchNorm2d(in_ch//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation),\n",
    "            nn.BatchNorm2d(1)\n",
    "            )\n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x1 = self.attn1(x)\n",
    "        print(x1.shape)\n",
    "        x1 = x1.div(math.sqrt(self.in_ch))\n",
    "        x1 = self.act(x1)\n",
    "        return x1 * x\n",
    "    \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "219eb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0525, 0.0979, 0.1569,  ..., 0.0582, 0.0247, 0.0160],\n",
       "          [0.0727, 0.1608, 0.0610,  ..., 0.1571, 0.1218, 0.1418],\n",
       "          [0.1507, 0.0386, 0.1734,  ..., 0.1465, 0.0286, 0.0477],\n",
       "          ...,\n",
       "          [0.1480, 0.1568, 0.0321,  ..., 0.0315, 0.0649, 0.0335],\n",
       "          [0.1738, 0.0994, 0.0688,  ..., 0.0802, 0.0657, 0.0310],\n",
       "          [0.0529, 0.0835, 0.1130,  ..., 0.1761, 0.1584, 0.0418]]],\n",
       "\n",
       "\n",
       "        [[[0.1763, 0.0707, 0.1292,  ..., 0.0475, 0.1614, 0.0835],\n",
       "          [0.0437, 0.0608, 0.0600,  ..., 0.1288, 0.1687, 0.0706],\n",
       "          [0.1224, 0.1491, 0.0600,  ..., 0.1608, 0.0421, 0.1761],\n",
       "          ...,\n",
       "          [0.0551, 0.0708, 0.0202,  ..., 0.0822, 0.0533, 0.1279],\n",
       "          [0.1265, 0.1765, 0.0488,  ..., 0.1384, 0.0031, 0.1202],\n",
       "          [0.0876, 0.0008, 0.0861,  ..., 0.1241, 0.1249, 0.0756]]],\n",
       "\n",
       "\n",
       "        [[[0.0253, 0.1442, 0.1468,  ..., 0.0377, 0.1401, 0.0757],\n",
       "          [0.0853, 0.1156, 0.1075,  ..., 0.0927, 0.0535, 0.0732],\n",
       "          [0.0816, 0.0781, 0.1404,  ..., 0.0458, 0.1575, 0.1125],\n",
       "          ...,\n",
       "          [0.0978, 0.0072, 0.0699,  ..., 0.1381, 0.0222, 0.1401],\n",
       "          [0.0387, 0.0832, 0.0521,  ..., 0.0437, 0.1209, 0.0474],\n",
       "          [0.1190, 0.0837, 0.1650,  ..., 0.0793, 0.1126, 0.0467]]],\n",
       "\n",
       "\n",
       "        [[[0.1444, 0.0108, 0.0325,  ..., 0.1174, 0.0546, 0.0930],\n",
       "          [0.0820, 0.1557, 0.0896,  ..., 0.0262, 0.1718, 0.0462],\n",
       "          [0.1494, 0.0458, 0.1277,  ..., 0.0226, 0.1137, 0.1222],\n",
       "          ...,\n",
       "          [0.0195, 0.0378, 0.0079,  ..., 0.0484, 0.0214, 0.1165],\n",
       "          [0.0598, 0.0500, 0.1177,  ..., 0.0100, 0.0995, 0.0458],\n",
       "          [0.1638, 0.1396, 0.0530,  ..., 0.0983, 0.0518, 0.0033]]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand([4,32,100,100])\n",
    "x1=torch.rand([4,1,100,100])\n",
    "y=x1.div(math.sqrt(32))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fec40786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([4, 1, 100, 100])\n",
    "x1=torch.rand([4, 100, 100, 100])\n",
    "l=x1*x\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8df8adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([0.4996, 0.5009, 0.5044])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand([3,100,100])\n",
    "y=torch.mean(x,dim=2)\n",
    "y=torch.mean(y,dim=1)\n",
    "\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb35c42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,4,9,16])\n",
    "x1=torch.tensor([1,2,3,4])\n",
    "y=x.div(x1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1186eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 50, 50])\n",
      "torch.Size([4, 1, 50, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0761, 0.0557, 0.0000],\n",
       "          [0.0754, 0.0228, 0.0540,  ..., 0.0000, 0.0423, 0.0297],\n",
       "          [0.0134, 0.0000, 0.0666,  ..., 0.0000, 0.1152, 0.0134],\n",
       "          ...,\n",
       "          [0.0017, 0.0431, 0.0304,  ..., 0.0056, 0.0134, 0.0787],\n",
       "          [0.0668, 0.0147, 0.0264,  ..., 0.0549, 0.0182, 0.0000],\n",
       "          [0.0000, 0.0534, 0.0000,  ..., 0.0570, 0.0794, 0.0180]]],\n",
       "\n",
       "\n",
       "        [[[0.0416, 0.0327, 0.0473,  ..., 0.0161, 0.0649, 0.0689],\n",
       "          [0.0236, 0.0064, 0.0248,  ..., 0.0000, 0.0000, 0.0131],\n",
       "          [0.0000, 0.0332, 0.0000,  ..., 0.0000, 0.0215, 0.0834],\n",
       "          ...,\n",
       "          [0.0556, 0.0366, 0.0503,  ..., 0.0465, 0.0120, 0.0710],\n",
       "          [0.0284, 0.0265, 0.0335,  ..., 0.0000, 0.0463, 0.0489],\n",
       "          [0.0000, 0.0000, 0.0087,  ..., 0.0000, 0.0097, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0045, 0.0000, 0.0334,  ..., 0.0878, 0.0000, 0.0459],\n",
       "          [0.1276, 0.0626, 0.0277,  ..., 0.0323, 0.0000, 0.0000],\n",
       "          [0.0136, 0.0749, 0.0000,  ..., 0.0658, 0.0338, 0.0164],\n",
       "          ...,\n",
       "          [0.0460, 0.0000, 0.0678,  ..., 0.0183, 0.0341, 0.0000],\n",
       "          [0.0185, 0.0485, 0.0723,  ..., 0.0326, 0.0000, 0.0059],\n",
       "          [0.0000, 0.0378, 0.0000,  ..., 0.0720, 0.1014, 0.0501]]],\n",
       "\n",
       "\n",
       "        [[[0.0763, 0.0142, 0.0422,  ..., 0.0615, 0.0183, 0.0000],\n",
       "          [0.0273, 0.0435, 0.0048,  ..., 0.0000, 0.0673, 0.0455],\n",
       "          [0.0140, 0.0582, 0.0054,  ..., 0.0467, 0.0295, 0.0619],\n",
       "          ...,\n",
       "          [0.0000, 0.0906, 0.0805,  ..., 0.0000, 0.0620, 0.0000],\n",
       "          [0.0000, 0.0953, 0.0326,  ..., 0.0509, 0.0000, 0.0725],\n",
       "          [0.0123, 0.0000, 0.0643,  ..., 0.0281, 0.0721, 0.0159]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True, h_max=1):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "        self.h_max = h_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) * self.h_max / 6\n",
    "    \n",
    "class scale_attention_block(nn.Module): \n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.pool=nn.AvgPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.relu=nn.ReLU()\n",
    "        self.h_sigmoid=h_sigmoid()\n",
    "    def forward(self, x):\n",
    "        x=self.pool(x)\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.h_sigmoid((self.relu(self.conv2(x))))\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e165506",
   "metadata": {},
   "outputs": [],
   "source": [
    "## channel Attention\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self,in_ch,kernel_size=1,stride=1,dilation=1):\n",
    "        super(attention_block,self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch//2, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.conv2= nn.Conv2d(in_ch//2, 1, kernel_size=kernel_size,stride=stride,bias=False,dilation=dilation)\n",
    "            \n",
    "            \n",
    "        self.act = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x =self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.conv2 (x)\n",
    "        print(x.shape)\n",
    "       \n",
    "       \n",
    "        return x\n",
    "        \n",
    "x=torch.rand([4,32,100,100])\n",
    "model=attention_block(in_ch=32)\n",
    "model(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b52e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 2736, 1824])\n"
     ]
    }
   ],
   "source": [
    "### CBAM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "           \n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "x=torch.rand([4,32,2736,1824])\n",
    "model=SpatialAttention(kernel_size=3)\n",
    "model1=ChannelAttention(in_planes=32)\n",
    "op=model1(x)*x\n",
    "op=model(op)*op\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ec1c5",
   "metadata": {},
   "source": [
    "# Loss Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "132e8222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_shape torch.Size([4, 4, 100, 100])\n",
      "inter1 shape torch.Size([4, 4, 100, 100])\n",
      "inter 2 shape torch.Size([4, 4])\n",
      "union torch.Size([4, 4, 100, 100])\n",
      "loss tensor(0.0021)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9979)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dice Loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class weighted_dice_loss(nn.Module):\n",
    "    def __init__(self, n_classes,weights = None):\n",
    "        super(weighted_dice_loss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.weights = weights\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, target, logit):\n",
    "        # logit => N x Classes x H x W\n",
    "        # target => N x H x W\n",
    "\n",
    "        N = len(logit)\n",
    "        #print(N)\n",
    "        #print('target',target.dtype)\n",
    "        #print('logit',logit.dtype)\n",
    "        pred = torch.nn.functional.softmax(logit,dim=1)\n",
    "        print('pred_shape',pred.shape)\n",
    "        #print('pred',pred.dtype)\n",
    "        #target = torch.LongTensor(target).detach().cpu()\n",
    "        #target_onehot = self.to_one_hot(target, self.n_classes)\n",
    "\n",
    "        # Numerator Product\n",
    "        inter = 2*pred * target\n",
    "        print('inter1 shape',inter.shape)\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        inter = inter.view(N, self.n_classes, -1).sum(2)\n",
    "        print('inter 2 shape',inter.shape)\n",
    "\n",
    "        # Denominator\n",
    "        union = pred + target \n",
    "        print('union',union.shape)\n",
    "        # Sum over all pixels N x C x H x W => N x C\n",
    "        union = union.view(N, self.n_classes, -1).sum(2)\n",
    "        inter = inter * self.weights \n",
    "        union = union * self.weights\n",
    "        loss = inter / (union + 1)\n",
    "        print('loss',loss.mean())\n",
    "\n",
    "\n",
    "        # Return average loss over classes and batch\n",
    "        return 1-loss.mean()\n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "dice_loss_train = weighted_dice_loss(4,weights=weights)   \n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss2=  dice_loss_train(x,y)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e5395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "tensor(-0.0075)\n"
     ]
    }
   ],
   "source": [
    "## dice loss simplified\n",
    "class dice_loss(nn.Module):\n",
    "    def __init__(self,n_class,weights):\n",
    "        super(dice_loss,self).__init__()\n",
    "        self.weights=weights\n",
    "        self.n_class=n_class\n",
    "        \n",
    "    def forward(self,mask,output):\n",
    "        pred=torch.nn.functional.softmax(output,dim=1)\n",
    "        inter=2*mask*pred\n",
    "        inter=inter.view(inter.shape[0],inter.shape[1],-1).sum(2)\n",
    "        print(inter.shape)\n",
    "        \n",
    "        union=pred+mask\n",
    "        union=union.view(union.shape[0],union.shape[1],-1).sum(2)\n",
    "        print(union.shape)\n",
    "        inter = inter * self.weights \n",
    "        union = union * self.weights\n",
    "        loss=inter/(union+1)\n",
    "        loss=1-loss.mean()\n",
    "        print(loss)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "dice_loss_t = dice_loss(4,weights=weights)   \n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss2=  dice_loss_t(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c381e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn([4,4,100,100])\n",
    "y=x.view(4,4,-1).sum(2)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f087b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-6fc7da1ccfe0>:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y=torch.nn.functional.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones([1,4])\n",
    "print(x)\n",
    "y=torch.nn.functional.softmax(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f99a8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3941, -1.4198, -2.1953, -0.8406,  0.1629],\n",
      "        [ 1.2566,  1.4996, -0.4067,  0.3345, -0.4112],\n",
      "        [ 2.1165,  0.3435, -0.7622, -1.0368, -0.2451]], requires_grad=True)\n",
      "tensor([[-1.3633, -2.3890, -3.1645, -1.8098, -0.8063],\n",
      "        [-1.1154, -0.8725, -2.7787, -2.0375, -2.7832],\n",
      "        [-0.3097, -2.0827, -3.1883, -3.4630, -2.6713]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor(2.0749, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Negative log likelihood loss>>> To take log the probability value after softmax and add the probability value of the correct answer to the average\n",
    "### formual>>>>>>>\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3,5, requires_grad=True)\n",
    "target=torch.tensor([0,2,1])\n",
    "print(input)\n",
    "x=m(input)\n",
    "print(x)\n",
    "loss = nn.NLLLoss()\n",
    "output = loss(x, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06245ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "input torch.Size([4, 4, 10000])\n",
      "target torch.Size([4, 10000])\n",
      "torch.Size([4, 10000])\n",
      "logpt torch.Size([4, 4, 10000])\n",
      "logpt----- torch.Size([4, 4, 10000])\n",
      "tensor(1.0837)\n"
     ]
    }
   ],
   "source": [
    "### focal Loss\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=3, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.reduction = True\n",
    "\n",
    "    def forward(self, input,target):\n",
    "        \"\"\"\n",
    "        input: [N, C], float32\n",
    "        target: [N, ], int64\n",
    "        \"\"\"\n",
    "        N = input.size(0)\n",
    "        C = input.size(1)\n",
    "        print(N)\n",
    "        print(C)\n",
    "        #input = input.permute(2,3,0,1)\n",
    "        input = input.view(N,C,-1)\n",
    "        print('input',input.shape)\n",
    "        #print(input.size())\n",
    "        \n",
    "        _,target = target.max(dim=1)\n",
    "        #print(target.size())\n",
    "        target = target.view(N,-1)\n",
    "        print('target',target.shape)\n",
    "        print(target.size())\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        print('logpt',logpt.shape)\n",
    "        pt = torch.exp(logpt)\n",
    "        logpt = (1-pt)**self.gamma * logpt\n",
    "        print('logpt-----',logpt.shape)\n",
    "        loss = F.nll_loss(logpt, target, self.weight) #negative log likelihood loss\n",
    "        return loss\n",
    "\n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "focal_loss = FocalLoss(weight=weights).cuda()\n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "\n",
    "loss=  focal_loss(x,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "85709c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 10000])\n",
      "torch.Size([4, 10000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0957)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## focal loss simplified\n",
    "class focal_loss(nn.Module):\n",
    "    def __init__(self,weights,gamma=3):\n",
    "        super(focal_loss,self).__init__()\n",
    "        self.weights=weights\n",
    "        self.gamma=gamma\n",
    "        \n",
    "    def forward(self,label,output):\n",
    "        output=output.view(output.shape[0],output.shape[1],-1)\n",
    "        print(output.shape)\n",
    "        log=torch.nn.functional.log_softmax(output,dim=1)\n",
    "        pt=torch.exp(log)\n",
    "        logpt=(1-pt)**self.gamma*log\n",
    "        \n",
    "        _,label=label.max(dim=1)\n",
    "        label=label.view(label.shape[0],-1)\n",
    "        print(label.shape)\n",
    "        \n",
    "        loss = F.nll_loss(logpt, label, self.weights) #negative log likelihood loss\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "weights = torch.FloatTensor([1.0,1.0,1.0,1.0])\n",
    "focal_loss = focal_loss(weights=weights).cuda()\n",
    "x=torch.randn([4,4,100,100])\n",
    "y=torch.randn([4,4,100,100])\n",
    "focal_loss(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085078b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## boundary loss\n",
    "def one_hot(label, n_classes, requires_grad=True):\n",
    "    \"\"\"Return One Hot Label\"\"\"\n",
    "    device = label.device\n",
    "    one_hot_label = torch.eye(\n",
    "        n_classes, device=device, requires_grad=requires_grad)[label]\n",
    "    one_hot_label = one_hot_label.transpose(1, 3).transpose(2, 3)\n",
    "\n",
    "    return one_hot_label\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"Boundary Loss proposed in:\n",
    "    Alexey Bokhovkin et al., Boundary Loss for Remote Sensing Imagery Semantic Segmentation\n",
    "    https://arxiv.org/abs/1905.07852\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta0=3, theta=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta0 = theta0\n",
    "        self.theta = theta\n",
    "\n",
    "    @staticmethod\n",
    "    def to_one_hot(tensor, n_classes):\n",
    "        #tensor = torch.FloatTensor(tensor)\n",
    "        n, h, w = tensor.size()\n",
    "        # print('N H W',n,h,w)\n",
    "        zeros = torch.zeros(n, n_classes, h, w)\n",
    "        #zeros = torch.cuda.FloatTensor(tensor.size(0),n_classes,tensor.size(1),tensor.size(2)).zero_()\n",
    "        #view_tensor = tensor.view(n, 1, h, w)\n",
    "        view_tensor = torch.reshape(tensor,(n,-1))\n",
    "        #print(\"tensor reshape\", tensor.dtype)\n",
    "        ones = torch.ones(tensor.size())\n",
    "        one_hot = zeros.scatter_(1, tensor, ones)\n",
    "        return one_hot\n",
    "\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        \n",
    "\n",
    "        n, c, _, _ = pred.shape\n",
    "\n",
    "        # softmax so that predicted map can be distributed in [0, 1]\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "\n",
    "        # one-hot vector of ground truth\n",
    "        # gt = torch.LongTensor(gt).detach().cpu()\n",
    "        # gt = torch.LongTensor(gt.long().detach().cpu())\n",
    "        # one_hot_gt = self.to_one_hot(gt, c)\n",
    "        one_hot_gt = gt\n",
    "\n",
    "        # boundary map\n",
    "        gt_b = F.max_pool2d(\n",
    "            1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        gt_b -= 1 - one_hot_gt\n",
    "\n",
    "        pred_b = F.max_pool2d(\n",
    "            1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        pred_b -= 1 - pred\n",
    "\n",
    "        # extended boundary map\n",
    "        gt_b_ext = F.max_pool2d(\n",
    "            gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        pred_b_ext = F.max_pool2d(\n",
    "            pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "\n",
    "        # reshape\n",
    "        gt_b = gt_b.view(n, c, -1)\n",
    "        pred_b = pred_b.view(n, c, -1)\n",
    "        gt_b_ext = gt_b_ext.view(n, c, -1)\n",
    "        pred_b_ext = pred_b_ext.view(n, c, -1)\n",
    "\n",
    "        # Precision, Recall\n",
    "        P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
    "        R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
    "\n",
    "        # Boundary F1 Score\n",
    "        BF1 = 2 * P * R / (P + R + 1e-7)\n",
    "\n",
    "        # summing BF1 Score for each class and average over mini-batch\n",
    "        loss = torch.mean(1 - BF1)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d1be028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/home/arvind/Documents/gauge_200_backtest_results/cumulative_grade_5jan_all_cls.csv')\n",
    "df=df[['imei','manual_grade']]\n",
    "df1=df.drop_duplicates(subset=['imei'])\n",
    "df1.to_csv('/home/arvind/Documents/gauge_200_backtest_results/used_manual_grade_gauge_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2ff6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cumulative_grade_5jan_all_cls.csv')\n",
    "#df.head()\n",
    "df['front_grade_old']=df['front_grade']\n",
    "df=df[['imei','asset_id','front_grade_old']]\n",
    "df1=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cummulative_all_side_sourabh_front_model.csv')\n",
    "df1['front_grade_new']=df1['front_grade']\n",
    "df1=df1[['imei','asset_id','front_grade_new']]\n",
    "df2=df.merge(df1,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55f3152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')\n",
    "df1=pd.read_csv('/home/arvind/Documents/20_apr_compare_front_pred/cummulative_all_side_sourabh_front_model_1.csv')\n",
    "df1['front_grade_new_1']=df1['front_grade']\n",
    "df1=df1[['imei','asset_id','front_grade_new_1']]\n",
    "df2=df.merge(df1,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/20_apr_compare_front_pred/front_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b010945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/cumulative_grade_5jan_all_cls.xlsx',sheet_name='cumulative_grade_5jan_all_cls')\n",
    "#df.head()\n",
    "df['back_grade_old']=df['back_grade']\n",
    "df['pred_cumulative_grade_old']=df['pred_cumulative_grade']\n",
    "df=df[['imei','asset_id','back_grade_old','pred_cumulative_grade_old']]\n",
    "df1=pd.read_excel('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/cummulative_all_side_sourabh_back_model_val_acc_2.xlsx',sheet_name='cummulative_all_side_sourabh_back_model')\n",
    "df1['back_grade_new']=df1['back_grade']\n",
    "df1['pred_cumulative_grade_new']=df1['pred_cumulative_grade']\n",
    "df1=df1[['imei','asset_id','back_grade_new','pred_cumulative_grade_new','manual_grade']]\n",
    "df2=df1.merge(df,on=['imei','asset_id'],how='left')\n",
    "df2.to_csv('/home/arvind/Documents/gauge_200_backtest_results/3may_back_compared/back_compared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5067f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
